{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23be85de-dd44-4622-9ab9-96f0fd911dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd06fdb2-e6b0-4799-81db-a5efcca7763b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import copy\n",
    "#\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"The Graph to model the skeletons extracted by the Alpha-Pose.\n",
    "    Args:\n",
    "        - strategy: (string) must be one of the follow candidates\n",
    "            - uniform: Uniform Labeling,\n",
    "            - distance: Distance Partitioning,\n",
    "            - spatial: Spatial Configuration,\n",
    "        For more information, please refer to the section 'Partition Strategies'\n",
    "            in our paper (https://arxiv.org/abs/1801.07455).\n",
    "        - layout: (string) must be one of the follow candidates\n",
    "            - coco_cut: Is COCO format but cut 4 joints (L-R ears, L-R eyes) out.\n",
    "        - max_hop: (int) the maximal distance between two connected nodes.\n",
    "        - dilation: (int) controls the spacing between the kernel points.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layout='coco_cut',\n",
    "                 strategy='uniform',\n",
    "                 max_hop=1,\n",
    "                 dilation=1):\n",
    "        self.max_hop = max_hop\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.get_edge(layout)\n",
    "        self.hop_dis = get_hop_distance(self.num_node, self.edge, max_hop)\n",
    "        self.get_adjacency(strategy)\n",
    "\n",
    "    def get_edge(self, layout):\n",
    "        if layout == 'coco_cut':\n",
    "            self.num_node = 14\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_link = [(6, 4), (4, 2), (2, 13), (13, 1), (5, 3), (3, 1), (12, 10),\n",
    "                             (10, 8), (8, 2), (11, 9), (9, 7), (7, 1), (13, 0)]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 13\n",
    "        else:\n",
    "            raise ValueError('This layout is not supported!')\n",
    "\n",
    "    def get_adjacency(self, strategy):\n",
    "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
    "        adjacency = np.zeros((self.num_node, self.num_node))\n",
    "        for hop in valid_hop:\n",
    "            adjacency[self.hop_dis == hop] = 1\n",
    "        normalize_adjacency = normalize_digraph(adjacency)\n",
    "\n",
    "        if strategy == 'uniform':\n",
    "            A = np.zeros((1, self.num_node, self.num_node))\n",
    "            A[0] = normalize_adjacency\n",
    "            self.A = A\n",
    "        elif strategy == 'distance':\n",
    "            A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
    "            for i, hop in enumerate(valid_hop):\n",
    "                A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis ==\n",
    "                                                                hop]\n",
    "            self.A = A\n",
    "        elif strategy == 'spatial':\n",
    "            A = []\n",
    "            for hop in valid_hop:\n",
    "                a_root = np.zeros((self.num_node, self.num_node))\n",
    "                a_close = np.zeros((self.num_node, self.num_node))\n",
    "                a_further = np.zeros((self.num_node, self.num_node))\n",
    "                for i in range(self.num_node):\n",
    "                    for j in range(self.num_node):\n",
    "                        if self.hop_dis[j, i] == hop:\n",
    "                            if self.hop_dis[j, self.center] == self.hop_dis[i, self.center]:\n",
    "                                a_root[j, i] = normalize_adjacency[j, i]\n",
    "                            elif self.hop_dis[j, self.center] > self.hop_dis[i, self.center]:\n",
    "                                a_close[j, i] = normalize_adjacency[j, i]\n",
    "                            else:\n",
    "                                a_further[j, i] = normalize_adjacency[j, i]\n",
    "                if hop == 0:\n",
    "                    A.append(a_root)\n",
    "                else:\n",
    "                    A.append(a_root + a_close)\n",
    "                    A.append(a_further)\n",
    "            A = np.stack(A)\n",
    "            self.A = A\n",
    "            #self.A = np.swapaxes(np.swapaxes(A, 0, 1), 1, 2)\n",
    "        else:\n",
    "            raise ValueError(\"This strategy is not supported!\")\n",
    "\n",
    "\n",
    "def get_hop_distance(num_node, edge, max_hop=1):\n",
    "    A = np.zeros((num_node, num_node))\n",
    "    for i, j in edge:\n",
    "        A[j, i] = 1\n",
    "        A[i, j] = 1\n",
    "\n",
    "    # compute hop steps\n",
    "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
    "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(max_hop + 1)]\n",
    "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
    "    for d in range(max_hop, -1, -1):\n",
    "        hop_dis[arrive_mat[d]] = d\n",
    "    return hop_dis\n",
    "\n",
    "\n",
    "def normalize_digraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-1)\n",
    "    AD = np.dot(A, Dn)\n",
    "    return AD\n",
    "\n",
    "\n",
    "def normalize_undigraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-0.5)\n",
    "    DAD = np.dot(np.dot(Dn, A), Dn)\n",
    "    return DAD\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        - in_channel: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (int) Size of the graph convolving kernel.\n",
    "        - t_kernel_size: (int) Size of the temporal convolving kernel.\n",
    "        - t_stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - t_padding: (int, optional) Temporal zero-padding added to both sides of\n",
    "            the input. Default: 0\n",
    "        - t_dilation: (int, optional) Spacing between temporal kernel elements. Default: 1\n",
    "        - bias: (bool, optional) If `True`, adds a learnable bias to the output.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math:`(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph adjacency matrix in :math:`(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math:`(N, out_channels, T_{out}, V)`\n",
    "\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 t_kernel_size=1,\n",
    "                 t_stride=1,\n",
    "                 t_padding=0,\n",
    "                 t_dilation=1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              out_channels * kernel_size,\n",
    "                              kernel_size=(t_kernel_size, 1),\n",
    "                              padding=(t_padding, 0),\n",
    "                              stride=(t_stride, 1),\n",
    "                              dilation=(t_dilation, 1),\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.kernel_size, kc//self.kernel_size, t, v)\n",
    "        x = torch.einsum('nkctv,kvw->nctw', (x, A))\n",
    "\n",
    "        return x.contiguous()\n",
    "###########################################################\n",
    "class Channel_Attention(nn.Module):\n",
    "    def __init__(self,out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.atten = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Conv2d(out_channels,int(out_channels/4),1),\n",
    "            nn.BatchNorm2d(int(out_channels/4)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(int(out_channels/4),out_channels,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        \n",
    "        atten = self.atten(x)\n",
    "        # print(x.shape,atten.shape)\n",
    "        x = x*atten\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "###########################################################\n",
    "\n",
    "class st_gcn(nn.Module):\n",
    "    \"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (tuple) Size of the temporal convolving kernel and\n",
    "            graph convolving kernel.\n",
    "        - stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - dropout: (int, optional) Dropout rate of the final output. Default: 0\n",
    "        - residual: (bool, optional) If `True`, applies a residual mechanism.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math: `(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph Adjecency matrix in :math: `(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math: `(N, out_channels, T_{out}, V)`\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1,\n",
    "                 dropout=0,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        #print(kernel_size)(9, 3)\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "        #print(padding)(4, 0)\n",
    "\n",
    "        self.gcn = GraphConvolution(in_channels, out_channels, kernel_size[1])\n",
    "        self.tcn = nn.Sequential(nn.BatchNorm2d(out_channels),\n",
    "                                 nn.ReLU(inplace=False),\n",
    "                                 nn.Conv2d(out_channels,\n",
    "                                           out_channels,\n",
    "                                           (kernel_size[0], 1),\n",
    "                                           (stride, 1),\n",
    "                                           padding),\n",
    "                                 nn.BatchNorm2d(out_channels),\n",
    "                                 nn.Dropout(dropout, inplace=True),\n",
    "                                 )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=(stride, 1)),\n",
    "                                          nn.BatchNorm2d(out_channels)\n",
    "                                          )\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.channel_attention_module = Channel_Attention(out_channels) \n",
    "        \n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        # print(res)\n",
    "        x = self.gcn(x, A)\n",
    "        #print(\"x_in:\",x.size())\n",
    "        # x = self.tcn(x) + res\n",
    "        #print(\"x_out:\",x.size())\n",
    "        x = self.tcn(x)\n",
    "        x = self.channel_attention_module(x) + res\n",
    "        \n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class StreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of input channels.\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs. If `None` return pooling features of\n",
    "            the last st-gcn layer instead.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "        or If num_class is `None`: `(N, out_channels)`\n",
    "            :math:`out_channels` is number of out_channels of the last layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, graph_args, num_class=None,\n",
    "                 edge_importance_weighting=True, **kwargs):\n",
    "        super().__init__()\n",
    "        # Load graph.\n",
    "        graph = Graph(**graph_args)\n",
    "        A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # Networks.\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            \n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            # st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            # st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            # st_gcn(256, 256, kernel_size, 1, **kwargs)\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting.\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        if num_class is not None:\n",
    "            self.cls = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "        else:\n",
    "            self.cls = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization.\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = x.view(N, C, T, V)\n",
    "\n",
    "        # forward.\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = gcn(x, self.A * importance)\n",
    "        #(B: 32,256, 6 or 7, node: 14, )\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = self.cls(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        # output(x): (B, num_class)\n",
    "        return x\n",
    "\n",
    "\n",
    "class TwoStreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Two inputs spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :tuple of math:`((N, 3, T, V), (N, 2, T, V))`\n",
    "        for points and motions stream where.\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`in_channels` is data channels (3 is (x, y, score)), (2 is (mot_x, mot_y))\n",
    "            :math:`T` is a length of input sequence,\n",
    "            :math:`V` is the number of graph nodes,\n",
    "        - Output: :math:`(N, num_class)`\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_args, num_class, edge_importance_weighting=True,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.pts_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)#3 is x,y,z\n",
    "        self.mot_stream = StreamSpatialTemporalGraph(2, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)#2 is x,y\n",
    "\n",
    "        self.fcn = nn.Linear((256 * 2)+11, num_class)\n",
    "        self.sensor = CNN_BiLSTM(hidden_size=32,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\")\n",
    "        # print(\"errr\")\n",
    "        \n",
    "        \n",
    "        # self.attention1=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 128),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.LeakyReLU(inplace=False),\n",
    "        #     nn.Linear(128, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "        # self.attention2=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 128),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.ReLU(inplace=False),\n",
    "        #     nn.Linear(128, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "        # self.attention3=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 64),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(inplace=False),\n",
    "        #     nn.Linear(64, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "        # self.attention4=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 64),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(inplace=False),\n",
    "        #     nn.Linear(64, 64),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(inplace=False),\n",
    "        #     nn.Linear(64, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "        # self.attention5=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 128),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.GELU(),\n",
    "        #     nn.Linear(128, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out1 = self.pts_stream(inputs[0])\n",
    "        out2 = self.mot_stream(inputs[1])\n",
    "        out3 = self.sensor(inputs[2])\n",
    "        \n",
    "        #print(out1.size())torch.Size([32, 256])\n",
    "        #print(out2.size())torch.Size([32, 256])\n",
    "        concat = torch.cat([out1, out2, out3], dim=-1)\n",
    "    \n",
    "        \n",
    "        # concat =  self.attention1(concat)\n",
    "        # concat =  self.attention2(concat)\n",
    "        # concat =  self.attention3(concat)\n",
    "        # concat =  self.attention4(concat)\n",
    "        # concat =  self.attention5(concat)\n",
    "        \n",
    "        out = self.fcn(concat)\n",
    "        #print(out.size())\n",
    "        # return torch.sigmoid(out)\n",
    "        return F.softmax(out,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9787a671-a84f-4048-885e-33792e7ff5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "####1DCNN(時系列により)######\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(15, 16, kernel_size=5, padding=2), #batch,チャンネル、シーケンス 入力チャンネル=30, 出力チャンネル=16\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2))\n",
    "        self.fc = nn.Linear(32*7, 32)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)#torch.Size([32, 32, 7])\n",
    "        # x = x.view(x.size(0), -1)  # Flatten\n",
    "        # x = self.fc(x)torch.Size([32, 32])\n",
    "        # print(x.size())\n",
    "        return x\n",
    "####LSTM#####\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, input_size, reduce_rate = 1/8):\n",
    "        super(ChannelAttention,self).__init__()\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_size, int(input_size*reduce_rate)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(input_size*reduce_rate), input_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        weight = self.attention(x)\n",
    "        x = torch.einsum('bc,bc -> bc',(x,weight))\n",
    "        return x\n",
    "    \n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_prob, num_classes = 1, feature = \"last\"):\n",
    "        super(BiLSTM,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        # Bidirectional LSTM layer\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True,dropout=dropout_prob)\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_size*2)\n",
    "        self.channelattention = ChannelAttention(hidden_size*2)\n",
    "        \n",
    "        self.feature = feature\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_size*2,num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = self.attention(x)\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)  # Multiply by 2 for bidirectional\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm1(x, (h0, c0))\n",
    "        \n",
    "        \n",
    "        # out = self.meanovertime(out)\n",
    "        if self.feature==\"last\":\n",
    "            out = out[:, -1, :]\n",
    "        else:\n",
    "            out = torch.mean(out,axis=1,keepdim=False)\n",
    "        out = self.batchnorm(out)\n",
    "        out = self.channelattention(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "class CNN_BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, dropout_prob, num_classes=1, feature=\"last\"):\n",
    "        super(CNN_BiLSTM, self).__init__()\n",
    "        self.cnn = CNN1D()\n",
    "        self.bilstm = BiLSTM(input_size=32,hidden_size=64,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        x = x.permute(0,2,1)\n",
    "        cnn_out = self.cnn(x)\n",
    "        # print(cnn_out)\n",
    "        # cnn_out = cnn_out.unsqueeze(1)# LSTMに渡すために次元を調整 (batch, seq_len, feature)torch.Size([32, 1, 32])\n",
    "        # print(cnn_out.size())\n",
    "        cnn_out = cnn_out.permute(0,2,1)\n",
    "        lstm_out = self.bilstm(cnn_out)\n",
    "        return lstm_out\n",
    "    \n",
    "    \n",
    "# model = BiLSTM(input_size=4,hidden_size=125,num_layers=1,dropout_prob=0.3,num_classes=2,feature=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56021efb-ab32-4ee2-acd6-ca2bdf3a742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "from skeleton_transformer import SkeletonTransformer\n",
    "\n",
    "# class Ensemble(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.skeleton_transofrmer = SkeletonTransformer()\n",
    "#         self.signal_model = BiLST_CNN()\n",
    "        \n",
    "#     def forward(self,inputs):\n",
    "#         skeleton = self.skeleton_transofrmer.embedding(inputs[0].permute(0,4,2,3,1)).permute(0,4,2,3,1)\n",
    "#         skeleton = self.skeleton_transofrmer.extractor(skeleton)\n",
    "#         # output(skeleton): B,C,T,V,M\n",
    "#         skeleton = skeleton.permute(0,4,1,2,3).reshape(B*M,C,T,V)\n",
    "#         # global pooling\n",
    "#         skeleton = f.avg_pool2d(skeleton, skeleton.size()[2:])\n",
    "#         skeleton = skeleton.view(B, M, -1, 1, 1).mean(dim=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "class Ensemble(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.skeleton_transformer = SkeletonTransformer(n_joints=14,seq_len=30) # pts\n",
    "        # self.skeleton_transformer = SkeletonTransformer(n_joints=14,seq_len=29) # mot\n",
    "        self.signal_model = CNN_BiLSTM(hidden_size=32,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\")\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(num_classes*2,num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        out1 = self.skeleton_transofrmer(inputs[0])\n",
    "        out2 = self.signal_model(inputs[1])\n",
    "        concat = torch.cat([out1, out2], dim=-1) # (B, num_classes * stream)\n",
    "        out = self.fc(concat)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b69f5b5-e1c1-4ce2-8a3b-78938d78bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp=torch.randn(8,2,21,14)\n",
    "# inp=inp.cuda()\n",
    "\n",
    "# #print(a[1].shape)\n",
    "# a=model(inp)\n",
    "# print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "550b4242-1af7-454e-ab59-f25358984096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Skeleton_Sensor_Dataset(Dataset):\n",
    "    def __init__(self,skeleton_sensor_data,label):\n",
    "        self.skeleton_sensor_data = skeleton_sensor_data\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.skeleton_sensor_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        skeleton,sensor = self.skeleton_sensor_data[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        # print(f\"DEBUG {type(skeleton.dtype)}, {type(sensor.dtype)} {type(label.dtype)} \")\n",
    "        \n",
    "        if not isinstance(skeleton,torch.Tensor):\n",
    "            skeleton = torch.tensor(skeleton,dtype=torch.float32)\n",
    "            \n",
    "        if not isinstance(sensor,torch.Tensor):\n",
    "            sensor = torch.tensor(sensor,dtype=torch.float32)\n",
    "        \n",
    "        if not isinstance(label,torch.Tensor):\n",
    "            label = torch.tensor(label,dtype=torch.float32)\n",
    "            \n",
    "        skeleton = skeleton.permute(2,0,1)\n",
    "        return skeleton,sensor,label\n",
    "    \n",
    "class Skeleton_Sensor_Dataset_v2(Dataset):\n",
    "    def __init__(self,skeleton_sensor_data,label):\n",
    "        self.skeleton_sensor_data = skeleton_sensor_data\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.skeleton_sensor_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        skeleton,sensor = self.skeleton_sensor_data[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        # print(f\"DEBUG {type(skeleton.dtype)}, {type(sensor.dtype)} {type(label.dtype)} \")\n",
    "        \n",
    "        if not isinstance(skeleton,torch.Tensor):\n",
    "            skeleton = torch.tensor(skeleton,dtype=torch.float32)\n",
    "            \n",
    "        if not isinstance(sensor,torch.Tensor):\n",
    "            sensor = torch.tensor(sensor,dtype=torch.float32)\n",
    "        \n",
    "        if not isinstance(label,torch.Tensor):\n",
    "            label = torch.tensor(label,dtype=torch.float32)\n",
    "            \n",
    "        skeleton = skeleton.permute(2,0,1) # skeleton [num_sample, (time, vertex, xyz)] -> [num_sample, (xyz, time, vertex)]\n",
    "        return skeleton,sensor,label\n",
    "    \n",
    "def custom_collate_fn(batch):\n",
    "    skeletons = [item[0] for item in batch]\n",
    "    sensors = [item[1] for item in batch]\n",
    "    labels = [item[2] for item in batch]\n",
    "\n",
    "    skeletons = torch.stack(skeletons)\n",
    "    sensors = torch.stack(sensors)\n",
    "    labels = torch.stack(labels)  # 例: ラベルが整数である場合\n",
    "\n",
    "    return skeletons, sensors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3af4a8a-81c1-4421-a952-00f7ecd7df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFold_load_dataset(data_files, batch_size, split_size=0.2):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            fts, lbs = pickle.load(f)\n",
    "            features.append(fts)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "    \n",
    "    set_of_train_loader,set_of_valid_loader = [],[]\n",
    "\n",
    "    if split_size > 0:\n",
    "        if split_size < 1:\n",
    "            n_splits = int(1/split_size)\n",
    "        else:\n",
    "            n_splits = split_size\n",
    "        skf = StratifiedKFold(n_splits,random_state=42, shuffle=True)\n",
    "        \n",
    "        for train_index, test_index in skf.split(features,labels):\n",
    "            train_set = data.TensorDataset(torch.tensor(features[train_index], dtype=torch.float32),torch.tensor(labels[train_index], dtype=torch.int64))\n",
    "            valid_set = data.TensorDataset(torch.tensor(features[test_index], dtype=torch.float32),torch.tensor(labels[test_index], dtype=torch.int64))\n",
    "            train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "            valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "            \n",
    "            set_of_train_loader.append(train_loader)\n",
    "            set_of_valid_loader.append(valid_loader)\n",
    "            \n",
    "    return set_of_train_loader, set_of_valid_loader\n",
    "\n",
    "def KFold_load_dataset_v2(data_files, batch_size, split_size=0.2):\n",
    "    \"\"\"Load data files into torch DataLoader with K-Fold splitting.\"\"\"\n",
    "    videos = []\n",
    "    features, sensors, labels = [], [], []\n",
    "    \n",
    "    # データの読み込み\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            vid, fts, sr, lbs = pickle.load(f)\n",
    "            videos += vid\n",
    "            features.append(fts)\n",
    "            sensors.append(sr)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs, sr\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    sensors = np.concatenate(sensors, axis=0)\n",
    "    \n",
    "    labels = labels.astype(np.float32)  # データ型の変換\n",
    "\n",
    "    set_of_train_loader, set_of_valid_loader = [], []\n",
    "\n",
    "    if split_size > 0:\n",
    "        if split_size < 1:\n",
    "            n_splits = int(1 / split_size)\n",
    "        else:\n",
    "            n_splits = split_size\n",
    "        \n",
    "        # skf = StratifiedKFold(n_splits, random_state=42, shuffle=True)\n",
    "        skf = KFold(n_splits, random_state=42, shuffle=True)\n",
    "        for train_index, test_index in skf.split(features, labels):\n",
    "            train_samples = [(features[i], sensors[i]) for i in train_index]\n",
    "            valid_samples = [(features[i], sensors[i]) for i in test_index]\n",
    "            \n",
    "            train_set = Skeleton_Sensor_Dataset(train_samples, labels[train_index])\n",
    "            valid_set = Skeleton_Sensor_Dataset(valid_samples, labels[test_index])\n",
    "            \n",
    "            train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "            valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "            \n",
    "            set_of_train_loader.append(train_loader)\n",
    "            set_of_valid_loader.append(valid_loader)\n",
    "    \n",
    "    return set_of_train_loader, set_of_valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7d5bc12-a5fe-451e-a808-f7ea904d6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_files, batch_size, split_size=0.2):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    features,sensors, labels = [], [], []\n",
    "    for fil in data_files:\n",
    "        # print(fil)\n",
    "        with open(fil, 'rb') as f:\n",
    "            _ ,fts,sr,lbs = pickle.load(f)\n",
    "            videos += vid\n",
    "            features.append(fts)\n",
    "            sensors.append(sr)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs,sr\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    sensors = np.concatenate(sensors, axis=0)\n",
    "    # print(features.shape,labels.shape)\n",
    "    # print(f\"DEBUG {features.shape},{sensors.shape},{labels.shape}\")\n",
    "    labels = labels.astype(np.float32)\n",
    "    \n",
    "    samples = []\n",
    "    for feature,sensor in zip(features,sensors):\n",
    "        samples += [(feature,sensor)]\n",
    "    # samples = np.array(samples,dtype=object)\n",
    "    \n",
    "    if split_size > 0:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(samples, labels, test_size=split_size,random_state=9)\n",
    "        \n",
    "        # train_set = data.TensorDataset(torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "        #                                torch.tensor(y_train, dtype=torch.float32))\n",
    "        # valid_set = data.TensorDataset(torch.tensor(x_valid, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "        #                                torch.tensor(y_valid, dtype=torch.float32))\n",
    "        train_set = Skeleton_Sensor_Dataset(x_train,y_train)\n",
    "        valid_set = Skeleton_Sensor_Dataset(x_valid,y_valid)\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "    else:\n",
    "        # train_set = data.TensorDataset(torch.tensor(features, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "        #                                torch.tensor(labels, dtype=torch.float32))\n",
    "        train_set = Skeleton_Sensor_Dataset(features,labels)\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = None\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def load_dataset_v2(data_files, batch_size, split_size=0.2):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    videos = []\n",
    "    features,sensors, labels = [], [], []\n",
    "    for fil in data_files:\n",
    "        # print(fil)\n",
    "        with open(fil, 'rb') as f:\n",
    "            vid ,fts,sr, lbs = pickle.load(f)\n",
    "            videos += vid\n",
    "            features.append(fts)\n",
    "            sensors.append(sr)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs,sr\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    sensors = np.concatenate(sensors, axis=0)\n",
    "    # print(features.shape,labels.shape)\n",
    "    # print(f\"DEBUG {features.shape},{sensors.shape},{labels.shape}\")\n",
    "    labels = labels.astype(np.float32) # dtype : object -> float32\n",
    "    \n",
    "    if split_size > 0:\n",
    "        unique_video_names = np.unique(videos)\n",
    "        train_videos, test_videos= train_test_split(unique_video_names,test_size=split_size,random_state=9)\n",
    "\n",
    "        train_samples,valid_samples = [],[]\n",
    "        train_label,valid_label = [],[]\n",
    "        for video,feature,sensor,label in zip(videos,features,sensors,labels):\n",
    "            if video in train_videos:\n",
    "                train_samples += [(feature,sensor)]\n",
    "                train_label += [label]\n",
    "            else:\n",
    "                valid_samples += [(feature,sensor)]\n",
    "                valid_label += [label]\n",
    "        \n",
    "        train_set = Skeleton_Sensor_Dataset(train_samples,train_label)\n",
    "        valid_set = Skeleton_Sensor_Dataset(valid_samples,valid_label)\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True,)\n",
    "        valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "    \n",
    "    else:\n",
    "        samples = []\n",
    "        for feature,sensor in zip(features,sensors):\n",
    "            samples += [(feature,sensor)]\n",
    "        train_set = Skeleton_Sensor_Dataset(samples,labels)\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = None\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8eaefe-20d9-483d-812c-849cfe45b7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "number of params: 262091\n",
      "Epoch 0/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:48<00:00, 14.68it/s,  loss: 0.5517, accu: 0.8438]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.38it/s,  loss: 2.3565, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.6686, accu: 0.8300\n",
      " - Valid loss: 0.5992, accu: 0.8902\n",
      "0.8902200948634891\n",
      "Epoch 1/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:49<00:00, 14.67it/s,  loss: 0.5229, accu: 0.9688]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.42it/s,  loss: 0.9236, accu: 0.7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.5369, accu: 0.9070\n",
      " - Valid loss: 0.4990, accu: 0.9355\n",
      "0.9354754743174456\n",
      "Epoch 2/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:48<00:00, 14.67it/s,  loss: 0.5041, accu: 0.9062]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.45it/s,  loss: 2.0255, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4931, accu: 0.9382\n",
      " - Valid loss: 0.4704, accu: 0.9540\n",
      "0.9539854234150856\n",
      "Epoch 3/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:48<00:00, 14.68it/s,  loss: 0.4702, accu: 0.9375]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.45it/s,  loss: 2.1232, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4685, accu: 0.9557\n",
      " - Valid loss: 0.5167, accu: 0.9538\n",
      "0.9539854234150856\n",
      "Epoch 4/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:50<00:00, 14.63it/s,  loss: 0.4452, accu: 1.0000]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.28it/s,  loss: 2.2794, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4560, accu: 0.9648\n",
      " - Valid loss: 0.4466, accu: 0.9747\n",
      "0.9747078898658029\n",
      "Epoch 5/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:50<00:00, 14.63it/s,  loss: 0.4311, accu: 0.9688]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.38it/s,  loss: 0.8404, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4467, accu: 0.9707\n",
      " - Valid loss: 0.4691, accu: 0.9748\n",
      "0.9748235770476631\n",
      "Epoch 6/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:50<00:00, 14.63it/s,  loss: 0.4405, accu: 0.9688]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.29it/s,  loss: 0.6341, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4411, accu: 0.9746\n",
      " - Valid loss: 0.4445, accu: 0.9890\n",
      "0.9890241786210088\n",
      "Epoch 7/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:49<00:00, 14.67it/s,  loss: 0.4959, accu: 0.9375]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.33it/s,  loss: 2.2546, accu: 0.0625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4362, accu: 0.9778\n",
      " - Valid loss: 0.4444, accu: 0.9810\n",
      "0.9890241786210088\n",
      "Epoch 8/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:49<00:00, 14.67it/s,  loss: 0.4134, accu: 1.0000]\n",
      "valid:  15%|█▌        | 649/4322 [00:12<01:18, 46.93it/s,  loss: 0.4660, accu: 1.0000]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "train: 100%|██████████| 8643/8643 [09:48<00:00, 14.68it/s,  loss: 0.4950, accu: 0.9688]\n",
      "valid:   4%|▍         | 183/4322 [00:02<01:11, 57.65it/s,  loss: 0.4067, accu: 1.0000]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "train: 100%|██████████| 8643/8643 [09:49<00:00, 14.66it/s,  loss: 0.4020, accu: 1.0000]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.24it/s,  loss: 0.6720, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4289, accu: 0.9825\n",
      " - Valid loss: 0.5531, accu: 0.9912\n",
      "0.9911860828320223\n",
      "Epoch 11/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:50<00:00, 14.65it/s,  loss: 0.4225, accu: 1.0000]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.30it/s,  loss: 0.6279, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4268, accu: 0.9836\n",
      " - Valid loss: 0.4182, accu: 0.9921\n",
      "0.992133271633503\n",
      "Epoch 12/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:49<00:00, 14.65it/s,  loss: 0.3873, accu: 1.0000]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.29it/s,  loss: 0.7585, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4251, accu: 0.9846\n",
      " - Valid loss: 0.5139, accu: 0.9889\n",
      "0.992133271633503\n",
      "Epoch 13/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 8643/8643 [09:50<00:00, 14.64it/s,  loss: 0.4245, accu: 1.0000]\n",
      "valid: 100%|██████████| 4322/4322 [01:33<00:00, 46.34it/s,  loss: 0.6221, accu: 1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4238, accu: 0.9853\n",
      " - Valid loss: 0.4699, accu: 0.9916\n",
      "0.992133271633503\n",
      "Epoch 14/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  99%|█████████▊| 8533/8643 [09:28<00:07, 14.68it/s,  loss: 0.4197, accu: 1.0000]"
     ]
    }
   ],
   "source": [
    "#run the code\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "from skeleton_transformer import SkeletonTransformer\n",
    "\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "#二分割できる（訓練用とテスト用）\n",
    "\n",
    "#from pose_utils import motions_map\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# from Actionsrecognition.Models import *\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "save_folder = 'saved/GSTCAN_HAR_Kfold_transformer_conv'\n",
    "\n",
    "#device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"using\", device, \"device\")\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32 #32\n",
    "\n",
    "# DATA FILES.\n",
    "# Should be in format of\n",
    "#  inputs: (N_samples, time_steps, graph_node, channels),\n",
    "#  labels: (N_samples, num_class)\n",
    "#   and do some of normalizations on it. Default data create from:\n",
    "#       Data.create_dataset_(1-3).py\n",
    "# where\n",
    "#   time_steps: Number of frame input sequence, Default: 30\n",
    "#   graph_node: Number of node in skeleton, Default: 14\n",
    "#   channels: Inputs data (x, y and scores), Default: 3\n",
    "#   num_class: Number of pose class to train, Default: 7\n",
    "\n",
    "data_files = ['../Data_fall2/har30_1_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_2_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_3_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_4_sensor_new-set(labelXscrw).pkl',\n",
    "              # '../Data_fall2/har30_5_sensor_new-set(labelXscrw).pkl',]\n",
    "              '../Data_fall2/har30_6_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_7_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_8_sensor_new-set(labelXscrw).pkl',\n",
    "              # '../Data_fall2/har30_9_sensor_new-set(labelXscrw).pkl',]\n",
    "              '../Data_fall2/har30_10_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_11_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_12_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_13_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_14_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_15_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_16_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_17_sensor_new-set(labelXscrw).pkl']\n",
    "\n",
    "class_names = ['Falling_forwards_hands','Falling_forwards_knees','Falling_backwards','Falling_sidewards',\n",
    "              'Falling_sitting','Walking','Standing','Sitting','Picking','Jumping','Laying']\n",
    "# num_class = len(class_names)\n",
    "\n",
    "def k_fold_cross_subject_HAR_UP(data_files):\n",
    "    f_fold = {}\n",
    "    data_files = np.array(data_files)\n",
    "    \n",
    "    for i,(train_idx,test_idx) in KFold(n_split=5,shuffle=True,random_state=42).split(data_files):\n",
    "        train_pkl, test_pkl = data_files[train_idx], data_files[test_idx]\n",
    "        \n",
    "        train_subset_pkl, valid_subset_pkl = train_test_split(test_size=3,shuffle=True,random_state=42)\n",
    "        \n",
    "        f_fold[f\"{i+1}_fold\"]={\n",
    "            \"train\":train_subset_pkl,\n",
    "            \"valid\":valid_subset_pkl,\n",
    "            \"test\":test_pkl,\n",
    "        }\n",
    "        \n",
    "    return f_fold\n",
    "\n",
    "# f_fold[\"1_fold\"] = {\"train\":['../Data_fall2/har30_1_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_2_sensor_new-set(labelXscrw).pkl''../Data_fall2/har30_3_sensor_new-set(labelXscrw).pkl',...],\n",
    "#                     \"valid\":['../Data_fall2/har30_7_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_8_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_9_sensor_new-set(labelXscrw).pkl',...],\n",
    "#                     \"test\":['../Data_fall2/har30_10_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_11_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_12_sensor_new-set(labelXscrw).pkl',...]\n",
    "#                    }\n",
    "                    \n",
    "        \n",
    "\n",
    "\n",
    "def accuracy_batch(y_pred, y_true):\n",
    "    return (y_pred.argmax(1) == y_true.argmax(1)).mean()\n",
    "\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #save_folder = os.path.join(os.path.dirname(), save_folder)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    # print('Start')\n",
    "\n",
    "    # DATA.\n",
    "    set_of_train_loader,set_of_valid_loader = KFold_load_dataset_v2(data_files, batch_size,0.33)\n",
    "    # print(set_of_train_loader.size())\n",
    "    # train_loader, valid_loader = load_dataset_v2(data_files[0:1], batch_size,split_size=0.2) \n",
    "    for i,(train_loader,valid_loader) in enumerate(zip(set_of_train_loader,set_of_valid_loader)):\n",
    "        \n",
    "        dataloader = {'train': train_loader, 'valid': valid_loader, }\n",
    "\n",
    "        #print(train_loader.shape)\n",
    "\n",
    "        # MODEL.(list化)\n",
    "        graph_args = {'strategy': 'spatial'}\n",
    "        ## for sensor data\n",
    "        # model = BiLSTM(input_size=4,hidden_size=64,num_layers=1,dropout_prob=0.3,num_classes=2,feature=\"mean\").to(device)\n",
    "        # model = CNN_BiLSTM(hidden_size=32,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\").to(device)\n",
    "        # model = SkeletonTransformer(in_channels=3,n_joints=14,seq_len=30,num_classes=11,embedding_dim=32,n_block=6,head_dim=16,n_heads=8).to(device)\n",
    "        # model = TwoStreamSpatialTemporalGraph(graph_args, 11).to(device)\n",
    "        model = E\n",
    "        n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"number of params: {n_parameters}\")\n",
    "        # model = TwoStreamSpatialTemporalGraph(graph_args, 2).to(device)\n",
    "        # graph_args = {'strategy': 'uniform'}\n",
    "        #graph_args = {'strategy': 'distance'}\n",
    "        # print(\"err\")\n",
    "        #model = TwoStreamSpatialTemporalGraph(graph_args, num_class).to(device)\n",
    "        #model = TwoStreamSpatialTemporalGraph(graph_args, 8).to(device)\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "        # losser = torch.nn.BCELoss() #fall or no_fall\n",
    "        losser = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # TRAINING.\n",
    "        loss_list = {'train': [], 'valid': []}\n",
    "        accu_list = {'train': [], 'valid': []}\n",
    "        best_acc = -1\n",
    "        for e in range(epochs):\n",
    "            print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':\n",
    "                    model = set_training(model, True)\n",
    "                else:\n",
    "                    model = set_training(model, False)\n",
    "\n",
    "                run_loss = 0.0\n",
    "                run_accu = 0.0\n",
    "                with tqdm(dataloader[phase], desc=phase) as iterator:\n",
    "                    for info in iterator:\n",
    "                        # print(len(info))\n",
    "                        pts, ser, lbs = info\n",
    "                        # print(torch.any(torch.isnan(pts)))\n",
    "                        # Create motion input by distance of points (x, y) of the same node\n",
    "                        # in two frames.\n",
    "                        #print(\"err\")\n",
    "                        mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "\n",
    "                        mot = mot.to(device)\n",
    "                        pts = pts.to(device)\n",
    "                        ser = ser.to(device)\n",
    "                        # print(ser.size())\n",
    "                        # torch.Size([32, 30, 15])\n",
    "                        lbs = lbs.to(device)\n",
    "\n",
    "                        #print(pts.size())torch.Size([32, 3, 30, 14])\n",
    "                        #print(mot.size())torch.Size([32, 2, 29, 14])\n",
    "\n",
    "                        # Forward.\n",
    "                        # out = model((pts, mot))#タプル型\n",
    "                        # out = model(ser) # for sensor data\n",
    "                        pts = pts.unsqueeze(-1)\n",
    "                        out = model(pts)\n",
    "                        # out = model((pts, mot, ser))\n",
    "                        # out = stgcn_sensor_model((pts, mot,ser))\n",
    "\n",
    "                        #out = model(mot)#タプル型\n",
    "                        # print(lbs)\n",
    "\n",
    "                        # print(out)\n",
    "                        loss = losser(out, lbs)\n",
    "                        #print(\"err\")\n",
    "                        if phase == 'train':\n",
    "                            # Backward.\n",
    "                            model.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                        run_loss += loss.item()\n",
    "                        accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                              lbs.detach().cpu().numpy())\n",
    "                        run_accu += accu\n",
    "\n",
    "                        iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                            loss.item(), accu))\n",
    "                        iterator.update()\n",
    "                        #break\n",
    "                loss_list[phase].append(run_loss / len(iterator))\n",
    "                accu_list[phase].append(run_accu / len(iterator))\n",
    "                #print(accu_list)\n",
    "                #print(torch.max(accu_list))\n",
    "            if(best_acc < accu_list['valid'][-1]):\n",
    "                best_acc = accu_list['valid'][-1]\n",
    "                best_model = copy.deepcopy(model)\n",
    "                torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "                #break\n",
    "\n",
    "            print('Summary epoch:\\n - Train loss: {:.4f}, accu: {:.4f}\\n - Valid loss:'\n",
    "            ' {:.4f}, accu: {:.4f}'.format(loss_list['train'][-1], accu_list['train'][-1],\n",
    "            loss_list['valid'][-1], accu_list['valid'][-1]))\n",
    "#             print(best_acc)\n",
    "#             plt.figure()\n",
    "#             plt.plot(list(range(len(loss_list['train']))),loss_list['train'],label=\"train_loss\")\n",
    "#             plt.plot(list(range(len(loss_list['valid']))),loss_list['valid'],label=\"valid_loss\")\n",
    "#             plt.legend()\n",
    "#             plt.savefig(os.path.join(save_folder, f'musa-model_of_loss_report_ur.png'))\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "\n",
    "#             plt.figure()\n",
    "#             plt.plot(list(range(len(accu_list['train']))),accu_list['train'],label=\"train_acc\")\n",
    "#             plt.plot(list(range(len(accu_list['valid']))),accu_list['valid'],label=\"valid_acc\")\n",
    "#             plt.legend()\n",
    "#             plt.savefig(os.path.join(save_folder, f'musa-model_of_acc_report.png'))\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "#             df = pd.DataFrame([loss_list['train'],loss_list['valid']]) \n",
    "#             df.to_csv(os.path.join(save_folder, f'musa-model_of_acc_report.csv'))\n",
    "\n",
    "#             df = pd.DataFrame([accu_list['train'],accu_list['valid']])\n",
    "#             df.to_csv(os.path.join(save_folder, f'musa-model_of_accu_report.csv'))\n",
    "#             torch.save(best_model.state_dict(), os.path.join(save_folder, f'musa-model_of_{best_acc:.4f}_UR.pth'))\n",
    "            print(best_acc)\n",
    "            plt.figure()\n",
    "            plt.plot(list(range(len(loss_list['train']))),loss_list['train'],label=\"train_loss\")\n",
    "            plt.plot(list(range(len(loss_list['valid']))),loss_list['valid'],label=\"valid_loss\")\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_folder, f'stgcn-model_{i+1}of{len(set_of_train_loader)}_loss_report.png'))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(list(range(len(accu_list['train']))),accu_list['train'],label=\"train_acc\")\n",
    "            plt.plot(list(range(len(accu_list['valid']))),accu_list['valid'],label=\"valid_acc\")\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_folder, f'stgcn-model_{i+1}of{len(set_of_train_loader)}_acc_report.png'))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            df = pd.DataFrame([loss_list['train'],loss_list['valid']]) \n",
    "            df.to_csv(os.path.join(save_folder, f'stgcn-model_{i+1}of{len(set_of_train_loader)}_acc_report.csv'))\n",
    "\n",
    "            df = pd.DataFrame([accu_list['train'],accu_list['valid']])\n",
    "            df.to_csv(os.path.join(save_folder, f'stgcn-model_{i+1}of{len(set_of_train_loader)}_accu_report.csv'))\n",
    "\n",
    "            # SAVE.\n",
    "            '''\n",
    "            if(best_acc < accu_list['valid'][-1]):\n",
    "                best_acc = accu_list['valid'][-1]\n",
    "                torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "                '''\n",
    "            '''\n",
    "            plot_graphs(list(loss_list.values()), list(loss_list.keys()),\n",
    "                            'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                                loss_list['train'][-1], loss_list['valid'][-1]\n",
    "                            ), 'Loss', xlim=[0, epochs],\n",
    "                            save=os.path.join(save_folder, 'loss_graph.png'))\n",
    "            plot_graphs(list(accu_list.values()), list(accu_list.keys()),\n",
    "                            'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                                accu_list['train'][-1], accu_list['valid'][-1]\n",
    "                            ), 'Accu', xlim=[0, epochs],\n",
    "                            save=os.path.join(save_folder, 'accu_graph.png'))\n",
    "            '''\n",
    "                #break\n",
    "\n",
    "        # del train_loader, valid_loader\n",
    "\n",
    "        #model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model.pth',map_location=torch.device('cpu'))))\n",
    "        model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model_best.pth')))\n",
    "        # EVALUATION.\n",
    "        #URのときは全部コメント\n",
    "        # model = set_training(model, False)\n",
    "        # data_file = data_files[1]\n",
    "        # eval_loader, _ = load_dataset([data_file], 32)\n",
    "\n",
    "        print('Evaluation.')\n",
    "        run_loss = 0.0\n",
    "        run_accu = 0.0\n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        model = best_model\n",
    "        #with tqdm(eval_loader, desc='eval') as iterator:\n",
    "        #URFD\n",
    "        with tqdm(dataloader[phase], desc='eval') as iterator:\n",
    "            for pts,ser, lbs in iterator:\n",
    "                # print(lbs)\n",
    "                mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "                mot = mot.to(device)\n",
    "                pts = pts.to(device)\n",
    "                ser = ser.to(device)\n",
    "                lbs = lbs.to(device)\n",
    "\n",
    "                # out = model((pts, mot)) # for skeleton data\n",
    "                # out = model(ser) # for sensor data\n",
    "                pts = pts.unsqueeze(-1)\n",
    "                out = model(pts)\n",
    "                # out = model((pts, mot, ser))\n",
    "                # out = model(mot)################\n",
    "                loss = losser(out, lbs)\n",
    "\n",
    "                run_loss += loss.item()\n",
    "                accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                      lbs.detach().cpu().numpy())\n",
    "                run_accu += accu\n",
    "\n",
    "                y_preds.extend(out.argmax(1).detach().cpu().numpy())\n",
    "                y_trues.extend(lbs.argmax(1).cpu().numpy())\n",
    "\n",
    "                iterator.set_postfix_str('loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                    loss.item(), accu))\n",
    "                iterator.update()\n",
    "\n",
    "        run_loss = run_loss / len(iterator)\n",
    "        run_accu = run_accu / len(iterator)\n",
    "        print('Eval Loss {:.4f}, Accu: {:.4f}'.format(run_loss, run_accu))\n",
    "        print('Precision:', precision_score(y_trues, y_preds,average='micro'))\n",
    "        print('Recall:', recall_score(y_trues, y_preds,average='micro'))\n",
    "        print('F1-score:', f1_score(y_trues, y_preds,average='micro'))\n",
    "    #     tn, fp, fn, tp = metrics.confusion_matrix(y_trues, y_preds).ravel()\n",
    "    #     specificity  = tn / (tn + fp)\n",
    "    #     print('Specificity:', specificity)\n",
    "        print(classification_report(y_trues, y_preds,digits=5))\n",
    "        report=classification_report(y_trues,  y_preds, digits=5,output_dict=True)\n",
    "        report_df = pd.DataFrame(report).T\n",
    "        report_df.to_csv(os.path.join(save_folder, f'GSTCAN_{i+1}of{len(set_of_train_loader)}_{best_acc:.4f}_report.csv'))\n",
    "\n",
    "        cmx_data = confusion_matrix(y_trues, y_preds)\n",
    "\n",
    "        df_cmx = pd.DataFrame(cmx_data)\n",
    "\n",
    "        plt.figure()\n",
    "        sns.heatmap(df_cmx, annot=True)\n",
    "        plt.savefig(os.path.join(save_folder, f'GSTCAN_{i+1}of{len(set_of_train_loader)}_confution_matrix.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2182e94-9098-4695-bbe4-fb08dca700b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phase)Classification_Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968bdda-17ee-4890-a6da-7696a116332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader, _ = load_dataset(data_files[0:1], batch_size) #batch_size = 32\n",
    "\n",
    "valid_loader, train_loader_ = load_dataset(data_files[:1], batch_size, 0.2)\n",
    "#print(\"err\")\n",
    "train_loader = data.DataLoader(data.ConcatDataset([train_loader.dataset, train_loader_.dataset]),\n",
    "                               batch_size, shuffle=True)\n",
    "dataloader = {'train': train_loader, 'valid': valid_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60102b09-09ed-436b-a786-b0f5307fddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    " with tqdm(dataloader[phase], desc='eval') as iterator:\n",
    "        for pts, lbs in iterator:\n",
    "            mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "            print(mot.shape)\n",
    "            print(lbs)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b285d-a9a1-4aba-bdfb-7e642ace17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "print(\"__file__:{}\".format(os.path.dirname(__file__)))\n",
    "print(\"dirname :{}\".format(os.path.dirname(__file__)))\n",
    "print(\"basename:{}\".format(os.path.basename(__file__)))\n",
    "print(\"files   :{}\".format(os.listdir(os.path.dirname(__file__))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c15c1b-ef62-4ef7-94ff-c73f2776332a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7011d1f-ad65-46d1-a4b7-8d7f37bb3405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80703760-e0a3-46dc-ba3e-cd0c65a883b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f87e18-72a7-492c-930b-4ecf2faf8530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65767253-d81e-45ca-8f44-2ed9a8436d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee71a25-80fb-4e05-8555-b3fab32384ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85408b7-19ed-4f92-a349-4c3362070285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4f929a-70be-4762-96ff-037251e3f7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82204c00-4353-4f53-95a1-8dcb868ca166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e83e7-fd71-4c03-a42c-3651fb47b9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f240bc70-93eb-41c1-a07c-bb288303b364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78720a9a-107a-4fa2-815b-496f46113083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(data_files, batch_size, phase=\"train\"):\n",
    "    videos=[]\n",
    "    features, sensors, labels = [], [], []\n",
    "    \n",
    "    # データの読み込み\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            vid, fts, sr, lbs = pickle.load(f)\n",
    "            videos += vid\n",
    "            features.append(fts)\n",
    "            sensors.append(sr)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs, sr\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    sensors = np.concatenate(sensors, axis=0)\n",
    "    \n",
    "    labels = labels.astype(np.float32)  # データ型の変換\n",
    "\n",
    "    data_sample = [(feature,sensor) for feature,sensor in zip(features,sensors)]\n",
    "    dataset = Skeleton_Sensor_Dataset(data_sample, labels)\n",
    "    dataloader = data.DataLoader(dataset, \n",
    "                                 batch_size, \n",
    "                                 shuffle=True if phase ==\"train\" else False,\n",
    "                                 drop_last=True if phase==\"train\" else False\n",
    "                                )\n",
    "    \n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fcd12d-cec4-45fa-ae44-8c49537a5579",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "number of params: 262091\n",
      "Epoch 0/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:31<00:00, 14.99it/s,  loss: 0.5215, accu: 0.9375]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.62it/s,  loss: 2.2904, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.6269, accu: 0.8526\n",
      " - Valid loss: 0.8891, accu: 0.7240\n",
      "0.7239895209580839\n",
      "Epoch 1/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:31<00:00, 14.99it/s,  loss: 0.4284, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.49it/s,  loss: 3.1701, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4888, accu: 0.9401\n",
      " - Valid loss: 0.9479, accu: 0.6793\n",
      "0.7239895209580839\n",
      "Epoch 2/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:33<00:00, 14.94it/s,  loss: 0.4481, accu: 0.9688]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.45it/s,  loss: 2.9434, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4543, accu: 0.9640\n",
      " - Valid loss: 0.9200, accu: 0.6979\n",
      "0.7239895209580839\n",
      "Epoch 3/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:33<00:00, 14.95it/s,  loss: 0.3901, accu: 0.9688]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.61it/s,  loss: 2.8032, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4400, accu: 0.9739\n",
      " - Valid loss: 0.8949, accu: 0.7138\n",
      "0.7239895209580839\n",
      "Epoch 4/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:32<00:00, 14.97it/s,  loss: 0.4007, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.58it/s,  loss: 3.7283, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4309, accu: 0.9800\n",
      " - Valid loss: 0.9156, accu: 0.7098\n",
      "0.7239895209580839\n",
      "Epoch 5/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:32<00:00, 14.98it/s,  loss: 0.4235, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.43it/s,  loss: 2.8891, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4258, accu: 0.9831\n",
      " - Valid loss: 0.8848, accu: 0.7221\n",
      "0.7239895209580839\n",
      "Epoch 6/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:35<00:00, 14.89it/s,  loss: 0.4010, accu: 0.9688]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.60it/s,  loss: 2.8326, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4216, accu: 0.9853\n",
      " - Valid loss: 1.0161, accu: 0.6691\n",
      "0.7239895209580839\n",
      "Epoch 7/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:31<00:00, 14.99it/s,  loss: 0.3919, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.36it/s,  loss: 3.1954, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4188, accu: 0.9870\n",
      " - Valid loss: 0.8880, accu: 0.7260\n",
      "0.7259855289421158\n",
      "Epoch 8/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:30<00:00, 15.02it/s,  loss: 0.4197, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.52it/s,  loss: 3.1150, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4166, accu: 0.9884\n",
      " - Valid loss: 0.9152, accu: 0.7015\n",
      "0.7259855289421158\n",
      "Epoch 9/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:33<00:00, 14.93it/s,  loss: 0.4028, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.33it/s,  loss: 2.7609, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4154, accu: 0.9894\n",
      " - Valid loss: 0.9521, accu: 0.6942\n",
      "0.7259855289421158\n",
      "Epoch 10/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:31<00:00, 14.99it/s,  loss: 0.3869, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.57it/s,  loss: 4.1137, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4141, accu: 0.9899\n",
      " - Valid loss: 1.0152, accu: 0.7103\n",
      "0.7259855289421158\n",
      "Epoch 11/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:32<00:00, 14.97it/s,  loss: 0.4351, accu: 0.9688]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.52it/s,  loss: 3.2440, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4128, accu: 0.9905\n",
      " - Valid loss: 0.8996, accu: 0.7311\n",
      "0.7310503992015968\n",
      "Epoch 12/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:32<00:00, 14.98it/s,  loss: 0.4095, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.53it/s,  loss: 3.2866, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4121, accu: 0.9910\n",
      " - Valid loss: 0.9577, accu: 0.7070\n",
      "0.7310503992015968\n",
      "Epoch 13/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [08:33<00:00, 14.93it/s,  loss: 0.4108, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:52<00:00, 47.55it/s,  loss: 3.1394, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4109, accu: 0.9916\n",
      " - Valid loss: 0.9820, accu: 0.6842\n",
      "0.7310503992015968\n",
      "Epoch 14/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  75%|███████▍  | 5742/7672 [06:12<02:08, 15.01it/s,  loss: 0.3812, accu: 1.0000]"
     ]
    }
   ],
   "source": [
    "#run the code\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "from skeleton_transformer import SkeletonTransformer\n",
    "\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "#二分割できる（訓練用とテスト用）\n",
    "\n",
    "#from pose_utils import motions_map\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# from Actionsrecognition.Models import *\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "save_folder = 'saved/GSTCAN_HAR_Kfold_transformer_convaaaaaa'\n",
    "\n",
    "#device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"using\", device, \"device\")\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32 #32\n",
    "\n",
    "# DATA FILES.\n",
    "# Should be in format of\n",
    "#  inputs: (N_samples, time_steps, graph_node, channels),\n",
    "#  labels: (N_samples, num_class)\n",
    "#   and do some of normalizations on it. Default data create from:\n",
    "#       Data.create_dataset_(1-3).py\n",
    "# where\n",
    "#   time_steps: Number of frame input sequence, Default: 30\n",
    "#   graph_node: Number of node in skeleton, Default: 14\n",
    "#   channels: Inputs data (x, y and scores), Default: 3\n",
    "#   num_class: Number of pose class to train, Default: 7\n",
    "\n",
    "data_files = ['../Data_fall2/har30_1_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_2_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_3_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_4_sensor_new-set(labelXscrw).pkl',\n",
    "              # '../Data_fall2/har30_5_sensor_new-set(labelXscrw).pkl',]\n",
    "              '../Data_fall2/har30_6_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_7_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_8_sensor_new-set(labelXscrw).pkl',\n",
    "              # '../Data_fall2/har30_9_sensor_new-set(labelXscrw).pkl',]\n",
    "              '../Data_fall2/har30_10_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_11_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_12_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_13_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_14_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_15_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_16_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_17_sensor_new-set(labelXscrw).pkl']\n",
    "\n",
    "class_names = ['Falling_forwards_hands','Falling_forwards_knees','Falling_backwards','Falling_sidewards',\n",
    "              'Falling_sitting','Walking','Standing','Sitting','Picking','Jumping','Laying']\n",
    "# num_class = len(class_names)\n",
    "\n",
    "def k_fold_cross_subject_HAR_UP(data_files):\n",
    "    f_fold = {}\n",
    "    data_files = np.array(data_files)\n",
    "    \n",
    "    for i,(train_idx,test_idx) in enumerate(KFold(n_splits=5,shuffle=True,random_state=42).split(data_files)):\n",
    "        train_pkl, test_pkl = data_files[train_idx], data_files[test_idx]\n",
    "        \n",
    "        train_subset_pkl, valid_subset_pkl = train_test_split(train_pkl,test_size=3,shuffle=True,random_state=42)\n",
    "        \n",
    "        f_fold[f\"{i+1}_fold\"]={\n",
    "            \"train\":train_subset_pkl,\n",
    "            \"valid\":valid_subset_pkl,\n",
    "            \"test\":test_pkl,\n",
    "        }\n",
    "        \n",
    "    return f_fold\n",
    "\n",
    "# f_fold[\"1_fold\"] = {\"train\":['../Data_fall2/har30_1_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_2_sensor_new-set(labelXscrw).pkl''../Data_fall2/har30_3_sensor_new-set(labelXscrw).pkl',...],\n",
    "#                     \"valid\":['../Data_fall2/har30_7_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_8_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_9_sensor_new-set(labelXscrw).pkl',...],\n",
    "#                     \"test\":['../Data_fall2/har30_10_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_11_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_12_sensor_new-set(labelXscrw).pkl',...]\n",
    "#                    }\n",
    "                    \n",
    "        \n",
    "\n",
    "\n",
    "def accuracy_batch(y_pred, y_true):\n",
    "    return (y_pred.argmax(1) == y_true.argmax(1)).mean()\n",
    "\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #save_folder = os.path.join(os.path.dirname(), save_folder)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    # print('Start')\n",
    "\n",
    "    # DATA.\n",
    "    set_of_train_loader,set_of_valid_loader = KFold_load_dataset_v2(data_files, batch_size,0.33)\n",
    "    # print(set_of_train_loader.size())\n",
    "    # train_loader, valid_loader = load_dataset_v2(data_files[0:1], batch_size,split_size=0.2) \n",
    "    # for i,(train_loader,valid_loader) in enumerate(zip(set_of_train_loader,set_of_valid_loader)):\n",
    "    \n",
    "    kfold_dict = k_fold_cross_subject_HAR_UP(data_files)  \n",
    "    for i in kfold_dict.keys():\n",
    "        \n",
    "        dataloader = dict()\n",
    "        for phase in [\"train\",\"valid\",\"test\"]:\n",
    "            pkl_files = kfold_dict[i][phase]\n",
    "            dataloader[phase] = build_dataloader(pkl_files,batch_size, phase=phase)\n",
    "\n",
    "\n",
    "        # MODEL.(list化)\n",
    "        graph_args = {'strategy': 'spatial'}\n",
    "        ## for sensor data\n",
    "        # model = BiLSTM(input_size=4,hidden_size=64,num_layers=1,dropout_prob=0.3,num_classes=2,feature=\"mean\").to(device)\n",
    "        # model = CNN_BiLSTM(hidden_size=32,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\").to(device)\n",
    "        model = SkeletonTransformer(in_channels=3,n_joints=14,seq_len=30,num_classes=11,embedding_dim=32,n_block=6,head_dim=16,n_heads=8).to(device)\n",
    "        # model = TwoStreamSpatialTemporalGraph(graph_args, 11).to(device)\n",
    "        # model = E\n",
    "        n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"number of params: {n_parameters}\")\n",
    "        # model = TwoStreamSpatialTemporalGraph(graph_args, 2).to(device)\n",
    "        # graph_args = {'strategy': 'uniform'}\n",
    "        #graph_args = {'strategy': 'distance'}\n",
    "        # print(\"err\")\n",
    "        #model = TwoStreamSpatialTemporalGraph(graph_args, num_class).to(device)\n",
    "        #model = TwoStreamSpatialTemporalGraph(graph_args, 8).to(device)\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "        # losser = torch.nn.BCELoss() #fall or no_fall\n",
    "        losser = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # TRAINING.\n",
    "        loss_list = {'train': [], 'valid': []}\n",
    "        accu_list = {'train': [], 'valid': []}\n",
    "        best_acc = -1\n",
    "        for e in range(epochs):\n",
    "            print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':\n",
    "                    model = set_training(model, True)\n",
    "                else:\n",
    "                    model = set_training(model, False)\n",
    "\n",
    "                run_loss = 0.0\n",
    "                run_accu = 0.0\n",
    "                with tqdm(dataloader[phase], desc=phase) as iterator:\n",
    "                    for info in iterator:\n",
    "                        # print(len(info))\n",
    "                        pts, ser, lbs = info\n",
    "                        # print(torch.any(torch.isnan(pts)))\n",
    "                        # Create motion input by distance of points (x, y) of the same node\n",
    "                        # in two frames.\n",
    "                        #print(\"err\")\n",
    "                        mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "\n",
    "                        mot = mot.to(device)\n",
    "                        pts = pts.to(device)\n",
    "                        ser = ser.to(device)\n",
    "                        # print(ser.size())\n",
    "                        # torch.Size([32, 30, 15])\n",
    "                        lbs = lbs.to(device)\n",
    "\n",
    "                        #print(pts.size())torch.Size([32, 3, 30, 14])\n",
    "                        #print(mot.size())torch.Size([32, 2, 29, 14])\n",
    "\n",
    "                        # Forward.\n",
    "                        # out = model((pts, mot))#タプル型\n",
    "                        # out = model(ser) # for sensor data\n",
    "                        pts = pts.unsqueeze(-1)\n",
    "                        out = model(pts)\n",
    "                        # out = model((pts, mot, ser))\n",
    "                        # out = stgcn_sensor_model((pts, mot,ser))\n",
    "\n",
    "                        #out = model(mot)#タプル型\n",
    "                        # print(lbs)\n",
    "\n",
    "                        # print(out)\n",
    "                        loss = losser(out, lbs)\n",
    "                        #print(\"err\")\n",
    "                        if phase == 'train':\n",
    "                            # Backward.\n",
    "                            model.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                        run_loss += loss.item()\n",
    "                        accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                              lbs.detach().cpu().numpy())\n",
    "                        run_accu += accu\n",
    "\n",
    "                        iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                            loss.item(), accu))\n",
    "                        iterator.update()\n",
    "                        #break\n",
    "                loss_list[phase].append(run_loss / len(iterator))\n",
    "                accu_list[phase].append(run_accu / len(iterator))\n",
    "                #print(accu_list)\n",
    "                #print(torch.max(accu_list))\n",
    "            if(best_acc < accu_list['valid'][-1]):\n",
    "                best_acc = accu_list['valid'][-1]\n",
    "                best_model = copy.deepcopy(model)\n",
    "                torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "                #break\n",
    "\n",
    "            print('Summary epoch:\\n - Train loss: {:.4f}, accu: {:.4f}\\n - Valid loss:'\n",
    "            ' {:.4f}, accu: {:.4f}'.format(loss_list['train'][-1], accu_list['train'][-1],\n",
    "            loss_list['valid'][-1], accu_list['valid'][-1]))\n",
    "#             print(best_acc)\n",
    "#             plt.figure()\n",
    "#             plt.plot(list(range(len(loss_list['train']))),loss_list['train'],label=\"train_loss\")\n",
    "#             plt.plot(list(range(len(loss_list['valid']))),loss_list['valid'],label=\"valid_loss\")\n",
    "#             plt.legend()\n",
    "#             plt.savefig(os.path.join(save_folder, f'musa-model_of_loss_report_ur.png'))\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "\n",
    "#             plt.figure()\n",
    "#             plt.plot(list(range(len(accu_list['train']))),accu_list['train'],label=\"train_acc\")\n",
    "#             plt.plot(list(range(len(accu_list['valid']))),accu_list['valid'],label=\"valid_acc\")\n",
    "#             plt.legend()\n",
    "#             plt.savefig(os.path.join(save_folder, f'musa-model_of_acc_report.png'))\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "#             df = pd.DataFrame([loss_list['train'],loss_list['valid']]) \n",
    "#             df.to_csv(os.path.join(save_folder, f'musa-model_of_acc_report.csv'))\n",
    "\n",
    "#             df = pd.DataFrame([accu_list['train'],accu_list['valid']])\n",
    "#             df.to_csv(os.path.join(save_folder, f'musa-model_of_accu_report.csv'))\n",
    "#             torch.save(best_model.state_dict(), os.path.join(save_folder, f'musa-model_of_{best_acc:.4f}_UR.pth'))\n",
    "            print(best_acc)\n",
    "            plt.figure()\n",
    "            plt.plot(list(range(len(loss_list['train']))),loss_list['train'],label=\"train_loss\")\n",
    "            plt.plot(list(range(len(loss_list['valid']))),loss_list['valid'],label=\"valid_loss\")\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_folder, f'stgcn-model_{i }of{len(kfold_dict)}_loss_report.png'))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(list(range(len(accu_list['train']))),accu_list['train'],label=\"train_acc\")\n",
    "            plt.plot(list(range(len(accu_list['valid']))),accu_list['valid'],label=\"valid_acc\")\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_folder, f'stgcn-model_{i}of{len(kfold_dict)}_acc_report.png'))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            df = pd.DataFrame([loss_list['train'],loss_list['valid']]) \n",
    "            df.to_csv(os.path.join(save_folder, f'stgcn-model_{i}of{len(kfold_dict)}_acc_report.csv'))\n",
    "\n",
    "            df = pd.DataFrame([accu_list['train'],accu_list['valid']])\n",
    "            df.to_csv(os.path.join(save_folder, f'stgcn-model_{i}of{len(kfold_dict)}_accu_report.csv'))\n",
    "\n",
    "            # SAVE.\n",
    "            '''\n",
    "            if(best_acc < accu_list['valid'][-1]):\n",
    "                best_acc = accu_list['valid'][-1]\n",
    "                torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "                '''\n",
    "            '''\n",
    "            plot_graphs(list(loss_list.values()), list(loss_list.keys()),\n",
    "                            'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                                loss_list['train'][-1], loss_list['valid'][-1]\n",
    "                            ), 'Loss', xlim=[0, epochs],\n",
    "                            save=os.path.join(save_folder, 'loss_graph.png'))\n",
    "            plot_graphs(list(accu_list.values()), list(accu_list.keys()),\n",
    "                            'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                                accu_list['train'][-1], accu_list['valid'][-1]\n",
    "                            ), 'Accu', xlim=[0, epochs],\n",
    "                            save=os.path.join(save_folder, 'accu_graph.png'))\n",
    "            '''\n",
    "                #break\n",
    "\n",
    "        # del train_loader, valid_loader\n",
    "\n",
    "        #model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model.pth',map_location=torch.device('cpu'))))\n",
    "        model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model_best.pth')))\n",
    "        # EVALUATION.\n",
    "        #URのときは全部コメント\n",
    "        # model = set_training(model, False)\n",
    "        # data_file = data_files[1]\n",
    "        # eval_loader, _ = load_dataset([data_file], 32)\n",
    "\n",
    "        print('Evaluation.')\n",
    "        run_loss = 0.0\n",
    "        run_accu = 0.0\n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        model = best_model\n",
    "        #with tqdm(eval_loader, desc='eval') as iterator:\n",
    "        #URFD\n",
    "        with tqdm(dataloader[\"test\"], desc='eval') as iterator:\n",
    "            for pts,ser, lbs in iterator:\n",
    "                # print(lbs)\n",
    "                mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "                mot = mot.to(device)\n",
    "                pts = pts.to(device)\n",
    "                ser = ser.to(device)\n",
    "                lbs = lbs.to(device)\n",
    "\n",
    "                # out = model((pts, mot)) # for skeleton data\n",
    "                # out = model(ser) # for sensor data\n",
    "                pts = pts.unsqueeze(-1)\n",
    "                out = model(pts)\n",
    "                # out = model((pts, mot, ser))\n",
    "                # out = model(mot)################\n",
    "                loss = losser(out, lbs)\n",
    "\n",
    "                run_loss += loss.item()\n",
    "                accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                      lbs.detach().cpu().numpy())\n",
    "                run_accu += accu\n",
    "\n",
    "                y_preds.extend(out.argmax(1).detach().cpu().numpy())\n",
    "                y_trues.extend(lbs.argmax(1).cpu().numpy())\n",
    "\n",
    "                iterator.set_postfix_str('loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                    loss.item(), accu))\n",
    "                iterator.update()\n",
    "\n",
    "        run_loss = run_loss / len(iterator)\n",
    "        run_accu = run_accu / len(iterator)\n",
    "        print('Eval Loss {:.4f}, Accu: {:.4f}'.format(run_loss, run_accu))\n",
    "        print('Precision:', precision_score(y_trues, y_preds,average='micro'))\n",
    "        print('Recall:', recall_score(y_trues, y_preds,average='micro'))\n",
    "        print('F1-score:', f1_score(y_trues, y_preds,average='micro'))\n",
    "    #     tn, fp, fn, tp = metrics.confusion_matrix(y_trues, y_preds).ravel()\n",
    "    #     specificity  = tn / (tn + fp)\n",
    "    #     print('Specificity:', specificity)\n",
    "        print(classification_report(y_trues, y_preds,digits=5))\n",
    "        report=classification_report(y_trues,  y_preds, digits=5,output_dict=True)\n",
    "        report_df = pd.DataFrame(report).T\n",
    "        report_df.to_csv(os.path.join(save_folder, f'GSTCAN_{i}of{len(kfold_dict)}_{best_acc:.4f}_report.csv'))\n",
    "\n",
    "        cmx_data = confusion_matrix(y_trues, y_preds)\n",
    "\n",
    "        df_cmx = pd.DataFrame(cmx_data)\n",
    "\n",
    "        plt.figure()\n",
    "        sns.heatmap(df_cmx, annot=True)\n",
    "        plt.savefig(os.path.join(save_folder, f'GSTCAN_{i}of{len(kfold_dict)}_confution_matrix.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abdb356-d496-4acf-b067-588e55b0c030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt113",
   "language": "python",
   "name": "pt113"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
