{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23be85de-dd44-4622-9ab9-96f0fd911dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd06fdb2-e6b0-4799-81db-a5efcca7763b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egawa/anaconda3/envs/pt113/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import warnings\n",
    "import copy\n",
    "#\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    \"\"\"The Graph to model the skeletons extracted by the Alpha-Pose.\n",
    "    Args:\n",
    "        - strategy: (string) must be one of the follow candidates\n",
    "            - uniform: Uniform Labeling,\n",
    "            - distance: Distance Partitioning,\n",
    "            - spatial: Spatial Configuration,\n",
    "        For more information, please refer to the section 'Partition Strategies'\n",
    "            in our paper (https://arxiv.org/abs/1801.07455).\n",
    "        - layout: (string) must be one of the follow candidates\n",
    "            - coco_cut: Is COCO format but cut 4 joints (L-R ears, L-R eyes) out.\n",
    "        - max_hop: (int) the maximal distance between two connected nodes.\n",
    "        - dilation: (int) controls the spacing between the kernel points.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 layout='coco_cut',\n",
    "                 strategy='uniform',\n",
    "                 max_hop=1,\n",
    "                 dilation=1):\n",
    "        self.max_hop = max_hop\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.get_edge(layout)\n",
    "        self.hop_dis = get_hop_distance(self.num_node, self.edge, max_hop)\n",
    "        self.get_adjacency(strategy)\n",
    "\n",
    "    def get_edge(self, layout):\n",
    "        if layout == 'coco_cut':\n",
    "            self.num_node = 14\n",
    "            self_link = [(i, i) for i in range(self.num_node)]\n",
    "            neighbor_link = [(6, 4), (4, 2), (2, 13), (13, 1), (5, 3), (3, 1), (12, 10),\n",
    "                             (10, 8), (8, 2), (11, 9), (9, 7), (7, 1), (13, 0)]\n",
    "            self.edge = self_link + neighbor_link\n",
    "            self.center = 13\n",
    "        else:\n",
    "            raise ValueError('This layout is not supported!')\n",
    "\n",
    "    def get_adjacency(self, strategy):\n",
    "        valid_hop = range(0, self.max_hop + 1, self.dilation)\n",
    "        adjacency = np.zeros((self.num_node, self.num_node))\n",
    "        for hop in valid_hop:\n",
    "            adjacency[self.hop_dis == hop] = 1\n",
    "        normalize_adjacency = normalize_digraph(adjacency)\n",
    "\n",
    "        if strategy == 'uniform':\n",
    "            A = np.zeros((1, self.num_node, self.num_node))\n",
    "            A[0] = normalize_adjacency\n",
    "            self.A = A\n",
    "        elif strategy == 'distance':\n",
    "            A = np.zeros((len(valid_hop), self.num_node, self.num_node))\n",
    "            for i, hop in enumerate(valid_hop):\n",
    "                A[i][self.hop_dis == hop] = normalize_adjacency[self.hop_dis ==\n",
    "                                                                hop]\n",
    "            self.A = A\n",
    "        elif strategy == 'spatial':\n",
    "            A = []\n",
    "            for hop in valid_hop:\n",
    "                a_root = np.zeros((self.num_node, self.num_node))\n",
    "                a_close = np.zeros((self.num_node, self.num_node))\n",
    "                a_further = np.zeros((self.num_node, self.num_node))\n",
    "                for i in range(self.num_node):\n",
    "                    for j in range(self.num_node):\n",
    "                        if self.hop_dis[j, i] == hop:\n",
    "                            if self.hop_dis[j, self.center] == self.hop_dis[i, self.center]:\n",
    "                                a_root[j, i] = normalize_adjacency[j, i]\n",
    "                            elif self.hop_dis[j, self.center] > self.hop_dis[i, self.center]:\n",
    "                                a_close[j, i] = normalize_adjacency[j, i]\n",
    "                            else:\n",
    "                                a_further[j, i] = normalize_adjacency[j, i]\n",
    "                if hop == 0:\n",
    "                    A.append(a_root)\n",
    "                else:\n",
    "                    A.append(a_root + a_close)\n",
    "                    A.append(a_further)\n",
    "            A = np.stack(A)\n",
    "            self.A = A\n",
    "            #self.A = np.swapaxes(np.swapaxes(A, 0, 1), 1, 2)\n",
    "        else:\n",
    "            raise ValueError(\"This strategy is not supported!\")\n",
    "\n",
    "\n",
    "def get_hop_distance(num_node, edge, max_hop=1):\n",
    "    A = np.zeros((num_node, num_node))\n",
    "    for i, j in edge:\n",
    "        A[j, i] = 1\n",
    "        A[i, j] = 1\n",
    "\n",
    "    # compute hop steps\n",
    "    hop_dis = np.zeros((num_node, num_node)) + np.inf\n",
    "    transfer_mat = [np.linalg.matrix_power(A, d) for d in range(max_hop + 1)]\n",
    "    arrive_mat = (np.stack(transfer_mat) > 0)\n",
    "    for d in range(max_hop, -1, -1):\n",
    "        hop_dis[arrive_mat[d]] = d\n",
    "    return hop_dis\n",
    "\n",
    "\n",
    "def normalize_digraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-1)\n",
    "    AD = np.dot(A, Dn)\n",
    "    return AD\n",
    "\n",
    "\n",
    "def normalize_undigraph(A):\n",
    "    Dl = np.sum(A, 0)\n",
    "    num_node = A.shape[0]\n",
    "    Dn = np.zeros((num_node, num_node))\n",
    "    for i in range(num_node):\n",
    "        if Dl[i] > 0:\n",
    "            Dn[i, i] = Dl[i]**(-0.5)\n",
    "    DAD = np.dot(np.dot(Dn, A), Dn)\n",
    "    return DAD\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GraphConvolution(nn.Module):\n",
    "    \"\"\"The basic module for applying a graph convolution.\n",
    "    Args:\n",
    "        - in_channel: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (int) Size of the graph convolving kernel.\n",
    "        - t_kernel_size: (int) Size of the temporal convolving kernel.\n",
    "        - t_stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - t_padding: (int, optional) Temporal zero-padding added to both sides of\n",
    "            the input. Default: 0\n",
    "        - t_dilation: (int, optional) Spacing between temporal kernel elements. Default: 1\n",
    "        - bias: (bool, optional) If `True`, adds a learnable bias to the output.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math:`(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph adjacency matrix in :math:`(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math:`(N, out_channels, T_{out}, V)`\n",
    "\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 t_kernel_size=1,\n",
    "                 t_stride=1,\n",
    "                 t_padding=0,\n",
    "                 t_dilation=1,\n",
    "                 bias=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv = nn.Conv2d(in_channels,\n",
    "                              out_channels * kernel_size,\n",
    "                              kernel_size=(t_kernel_size, 1),\n",
    "                              padding=(t_padding, 0),\n",
    "                              stride=(t_stride, 1),\n",
    "                              dilation=(t_dilation, 1),\n",
    "                              bias=bias)\n",
    "\n",
    "    def forward(self, x, A):\n",
    "        x = self.conv(x)\n",
    "        n, kc, t, v = x.size()\n",
    "        x = x.view(n, self.kernel_size, kc//self.kernel_size, t, v)\n",
    "        x = torch.einsum('nkctv,kvw->nctw', (x, A))\n",
    "\n",
    "        return x.contiguous()\n",
    "###########################################################\n",
    "class Channel_Attention(nn.Module):\n",
    "    def __init__(self,out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.atten = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Conv2d(out_channels,int(out_channels/4),1),\n",
    "            nn.BatchNorm2d(int(out_channels/4)),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(int(out_channels/4),out_channels,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        \n",
    "        atten = self.atten(x)\n",
    "        # print(x.shape,atten.shape)\n",
    "        x = x*atten\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "###########################################################\n",
    "\n",
    "class st_gcn(nn.Module):\n",
    "    \"\"\"Applies a spatial temporal graph convolution over an input graph sequence.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of channels in the input sequence data.\n",
    "        - out_channels: (int) Number of channels produced by the convolution.\n",
    "        - kernel_size: (tuple) Size of the temporal convolving kernel and\n",
    "            graph convolving kernel.\n",
    "        - stride: (int, optional) Stride of the temporal convolution. Default: 1\n",
    "        - dropout: (int, optional) Dropout rate of the final output. Default: 0\n",
    "        - residual: (bool, optional) If `True`, applies a residual mechanism.\n",
    "            Default: `True`\n",
    "    Shape:\n",
    "        - Inputs x: Graph sequence in :math: `(N, in_channels, T_{in}, V)`,\n",
    "                 A: Graph Adjecency matrix in :math: `(K, V, V)`,\n",
    "        - Output: Graph sequence out in :math: `(N, out_channels, T_{out}, V)`\n",
    "            where\n",
    "                :math:`N` is a batch size,\n",
    "                :math:`K` is the spatial kernel size, as :math:`K == kernel_size[1]`,\n",
    "                :math:`T_{in}/T_{out}` is a length of input/output sequence,\n",
    "                :math:`V` is the number of graph nodes.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1,\n",
    "                 dropout=0,\n",
    "                 residual=True):\n",
    "        super().__init__()\n",
    "        assert len(kernel_size) == 2\n",
    "        assert kernel_size[0] % 2 == 1\n",
    "        #print(kernel_size)(9, 3)\n",
    "        padding = ((kernel_size[0] - 1) // 2, 0)\n",
    "        #print(padding)(4, 0)\n",
    "\n",
    "        self.gcn = GraphConvolution(in_channels, out_channels, kernel_size[1])\n",
    "        self.tcn = nn.Sequential(nn.BatchNorm2d(out_channels),\n",
    "                                 nn.ReLU(inplace=False),\n",
    "                                 nn.Conv2d(out_channels,\n",
    "                                           out_channels,\n",
    "                                           (kernel_size[0], 1),\n",
    "                                           (stride, 1),\n",
    "                                           padding),\n",
    "                                 nn.BatchNorm2d(out_channels),\n",
    "                                 nn.Dropout(dropout, inplace=True),\n",
    "                                 )\n",
    "\n",
    "        if not residual:\n",
    "            self.residual = lambda x: 0\n",
    "        elif (in_channels == out_channels) and (stride == 1):\n",
    "            self.residual = lambda x: x\n",
    "        else:\n",
    "            self.residual = nn.Sequential(nn.Conv2d(in_channels,\n",
    "                                                    out_channels,\n",
    "                                                    kernel_size=1,\n",
    "                                                    stride=(stride, 1)),\n",
    "                                          nn.BatchNorm2d(out_channels)\n",
    "                                          )\n",
    "        self.relu = nn.ReLU(inplace=False)\n",
    "        self.channel_attention_module = Channel_Attention(out_channels) \n",
    "        \n",
    "    def forward(self, x, A):\n",
    "        res = self.residual(x)\n",
    "        # print(res)\n",
    "        x = self.gcn(x, A)\n",
    "        #print(\"x_in:\",x.size())\n",
    "        # x = self.tcn(x) + res\n",
    "        #print(\"x_out:\",x.size())\n",
    "        x = self.tcn(x)\n",
    "        x = self.channel_attention_module(x) + res\n",
    "        \n",
    "        return self.relu(x)\n",
    "\n",
    "\n",
    "class StreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - in_channels: (int) Number of input channels.\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs. If `None` return pooling features of\n",
    "            the last st-gcn layer instead.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, in_channels, T_{in}, V_{in})`\n",
    "        - Output: :math:`(N, num_class)` where\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`T_{in}` is a length of input sequence,\n",
    "            :math:`V_{in}` is the number of graph nodes,\n",
    "        or If num_class is `None`: `(N, out_channels)`\n",
    "            :math:`out_channels` is number of out_channels of the last layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, graph_args, num_class=None,\n",
    "                 edge_importance_weighting=True, **kwargs):\n",
    "        super().__init__()\n",
    "        # Load graph.\n",
    "        graph = Graph(**graph_args)\n",
    "        A = torch.tensor(graph.A, dtype=torch.float32, requires_grad=False)\n",
    "        self.register_buffer('A', A)\n",
    "\n",
    "        # Networks.\n",
    "        spatial_kernel_size = A.size(0)\n",
    "        temporal_kernel_size = 9\n",
    "        kernel_size = (temporal_kernel_size, spatial_kernel_size)\n",
    "        kwargs0 = {k: v for k, v in kwargs.items() if k != 'dropout'}\n",
    "\n",
    "        self.data_bn = nn.BatchNorm1d(in_channels * A.size(1))\n",
    "        self.st_gcn_networks = nn.ModuleList((\n",
    "            st_gcn(in_channels, 64, kernel_size, 1, residual=False, **kwargs0),\n",
    "            \n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            # st_gcn(64, 64, kernel_size, 1, **kwargs),\n",
    "            st_gcn(64, 128, kernel_size, 2, **kwargs),\n",
    "            st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            # st_gcn(128, 128, kernel_size, 1, **kwargs),\n",
    "            st_gcn(128, 256, kernel_size, 2, **kwargs),\n",
    "            st_gcn(256, 256, kernel_size, 1, **kwargs),\n",
    "            # st_gcn(256, 256, kernel_size, 1, **kwargs)\n",
    "        ))\n",
    "\n",
    "        # initialize parameters for edge importance weighting.\n",
    "        if edge_importance_weighting:\n",
    "            self.edge_importance = nn.ParameterList([\n",
    "                nn.Parameter(torch.ones(A.size()))\n",
    "                for i in self.st_gcn_networks\n",
    "            ])\n",
    "        else:\n",
    "            self.edge_importance = [1] * len(self.st_gcn_networks)\n",
    "\n",
    "        if num_class is not None:\n",
    "            self.cls = nn.Conv2d(256, num_class, kernel_size=1)\n",
    "        else:\n",
    "            self.cls = lambda x: x\n",
    "\n",
    "    def forward(self, x):\n",
    "        # data normalization.\n",
    "        N, C, T, V = x.size()\n",
    "        x = x.permute(0, 3, 1, 2).contiguous()  # (N, V, C, T)\n",
    "        x = x.view(N, V * C, T)\n",
    "        x = self.data_bn(x)\n",
    "        x = x.view(N, V, C, T)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        x = x.view(N, C, T, V)\n",
    "\n",
    "        # forward.\n",
    "        for gcn, importance in zip(self.st_gcn_networks, self.edge_importance):\n",
    "            x = gcn(x, self.A * importance)\n",
    "        #(B: 32,256, 6 or 7, node: 14, )\n",
    "        x = F.avg_pool2d(x, x.size()[2:])\n",
    "        x = self.cls(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TwoStreamSpatialTemporalGraph(nn.Module):\n",
    "    \"\"\"Two inputs spatial temporal graph convolutional networks.\n",
    "    Args:\n",
    "        - graph_args: (dict) Args map of `Actionsrecognition.Utils.Graph` Class.\n",
    "        - num_class: (int) Number of class outputs.\n",
    "        - edge_importance_weighting: (bool) If `True`, adds a learnable importance\n",
    "            weighting to the edges of the graph.\n",
    "        - **kwargs: (optional) Other parameters for graph convolution units.\n",
    "    Shape:\n",
    "        - Input: :tuple of math:`((N, 3, T, V), (N, 2, T, V))`\n",
    "        for points and motions stream where.\n",
    "            :math:`N` is a batch size,\n",
    "            :math:`in_channels` is data channels (3 is (x, y, score)), (2 is (mot_x, mot_y))\n",
    "            :math:`T` is a length of input sequence,\n",
    "            :math:`V` is the number of graph nodes,\n",
    "        - Output: :math:`(N, num_class)`\n",
    "    \"\"\"\n",
    "    def __init__(self, graph_args, num_class, edge_importance_weighting=True,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.pts_stream = StreamSpatialTemporalGraph(3, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)#3 is x,y,z\n",
    "        self.mot_stream = StreamSpatialTemporalGraph(2, graph_args, None,\n",
    "                                                     edge_importance_weighting,\n",
    "                                                     **kwargs)#2 is x,y\n",
    "        \n",
    "        # self.model = BiLSTM(input_size=4,hidden_size=64,num_layers=1,dropout_prob=0.3,num_classes=2,feature=\"mean\").to(device)\n",
    "        \n",
    "        self.fcn = nn.Linear(256 * 2, num_class)\n",
    "        # self.fcn = nn.Linear((256 * 2)+11, num_class)\n",
    "        # print(\"errr\")\n",
    "        \n",
    "        \n",
    "        # self.attention1=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 128),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.LeakyReLU(inplace=False),\n",
    "        #     nn.Linear(128, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "        # self.attention2=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 128),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.ReLU(inplace=False),\n",
    "        #     nn.Linear(128, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "        # self.attention3=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 64),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(inplace=False),\n",
    "        #     nn.Linear(64, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "        # self.attention4=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 64),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(inplace=False),\n",
    "        #     nn.Linear(64, 64),\n",
    "        #     nn.BatchNorm1d(64),\n",
    "        #     nn.ReLU(inplace=False),\n",
    "        #     nn.Linear(64, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "        # self.attention5=nn.Sequential(\n",
    "        #     nn.Linear(256 * 2, 128),\n",
    "        #     nn.BatchNorm1d(128),\n",
    "        #     nn.GELU(),\n",
    "        #     nn.Linear(128, 256 * 2),\n",
    "        #     nn.BatchNorm1d(256 * 2),\n",
    "        #     nn.Sigmoid(),\n",
    "        # )\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        out1 = self.pts_stream(inputs[0])\n",
    "        out2 = self.mot_stream(inputs[1])\n",
    "        \n",
    "        # out3 = self.model(input[3])\n",
    "        \n",
    "        #print(out1.size())torch.Size([32, 256])\n",
    "        #print(out2.size())torch.Size([32, 256])\n",
    "        concat = torch.cat([out1, out2], dim=-1)\n",
    "        # concat = torch.cat([out1, out2, out3], dim=-1)\n",
    "        \n",
    "        # concat =  self.attention1(concat)\n",
    "        # concat =  self.attention2(concat)\n",
    "        # concat =  self.attention3(concat)\n",
    "        # concat =  self.attention4(concat)\n",
    "        # concat =  self.attention5(concat)\n",
    "        \n",
    "        out = self.fcn(concat)\n",
    "        #print(out.size())\n",
    "        # return torch.sigmoid(out)\n",
    "        return F.softmax(out,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9787a671-a84f-4048-885e-33792e7ff5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "####1DCNN(時系列により)######\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(15, 16, kernel_size=5, padding=2), #batch,チャンネル、シーケンス 入力チャンネル=30, 出力チャンネル=16\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2))\n",
    "        self.fc = nn.Linear(32*7, 32)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)#torch.Size([32, 32, 7])\n",
    "        # x = x.view(x.size(0), -1)  # Flatten\n",
    "        # x = self.fc(x)torch.Size([32, 32])\n",
    "        # print(x.size())\n",
    "        return x\n",
    "####LSTM#####\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, input_size, reduce_rate = 1/8):\n",
    "        super(ChannelAttention,self).__init__()\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(input_size, int(input_size*reduce_rate)),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(int(input_size*reduce_rate), input_size),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        weight = self.attention(x)\n",
    "        x = torch.einsum('bc,bc -> bc',(x,weight))\n",
    "        return x\n",
    "    \n",
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout_prob, num_classes = 1, feature = \"last\"):\n",
    "        super(BiLSTM,self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        # Bidirectional LSTM layer\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True,dropout=dropout_prob)\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm1d(hidden_size*2)\n",
    "        self.channelattention = ChannelAttention(hidden_size*2)\n",
    "        \n",
    "        self.feature = feature\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_size*2,num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = self.attention(x)\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)  # Multiply by 2 for bidirectional\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm1(x, (h0, c0))\n",
    "        \n",
    "        \n",
    "        # out = self.meanovertime(out)\n",
    "        if self.feature==\"last\":\n",
    "            out = out[:, -1, :]\n",
    "        else:\n",
    "            out = torch.mean(out,axis=1,keepdim=False)\n",
    "        out = self.batchnorm(out)\n",
    "        out = self.channelattention(out)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "class CNN_BiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, num_layers, dropout_prob, num_classes=1, feature=\"last\"):\n",
    "        super(CNN_BiLSTM, self).__init__()\n",
    "        self.cnn = CNN1D()\n",
    "        self.bilstm = BiLSTM(input_size=32,hidden_size=64,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(x.size())\n",
    "        x = x.permute(0,2,1)\n",
    "        cnn_out = self.cnn(x)\n",
    "        # print(cnn_out)\n",
    "        # cnn_out = cnn_out.unsqueeze(1)# LSTMに渡すために次元を調整 (batch, seq_len, feature)torch.Size([32, 1, 32])\n",
    "        # print(cnn_out.size())\n",
    "        cnn_out = cnn_out.permute(0,2,1)\n",
    "        lstm_out = self.bilstm(cnn_out)\n",
    "        return lstm_out\n",
    "    \n",
    "    \n",
    "# model = BiLSTM(input_size=4,hidden_size=125,num_layers=1,dropout_prob=0.3,num_classes=2,feature=\"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b69f5b5-e1c1-4ce2-8a3b-78938d78bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp=torch.randn(8,2,21,14)\n",
    "# inp=inp.cuda()\n",
    "\n",
    "# #print(a[1].shape)\n",
    "# a=model(inp)\n",
    "# print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550b4242-1af7-454e-ab59-f25358984096",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Skeleton_Sensor_Dataset(Dataset):\n",
    "    def __init__(self,skeleton_sensor_data,label):\n",
    "        self.skeleton_sensor_data = skeleton_sensor_data\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.skeleton_sensor_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        skeleton,sensor = self.skeleton_sensor_data[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        # print(f\"DEBUG {type(skeleton.dtype)}, {type(sensor.dtype)} {type(label.dtype)} \")\n",
    "        \n",
    "        if not isinstance(skeleton,torch.Tensor):\n",
    "            skeleton = torch.tensor(skeleton,dtype=torch.float32)\n",
    "            \n",
    "        if not isinstance(sensor,torch.Tensor):\n",
    "            sensor = torch.tensor(sensor,dtype=torch.float32)\n",
    "        \n",
    "        if not isinstance(label,torch.Tensor):\n",
    "            label = torch.tensor(label,dtype=torch.float32)\n",
    "            \n",
    "        skeleton = skeleton.permute(2,0,1)\n",
    "        return skeleton,sensor,label\n",
    "    \n",
    "class Skeleton_Sensor_Dataset_v2(Dataset):\n",
    "    def __init__(self,skeleton_sensor_data,label):\n",
    "        self.skeleton_sensor_data = skeleton_sensor_data\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.skeleton_sensor_data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        skeleton,sensor = self.skeleton_sensor_data[idx]\n",
    "        label = self.label[idx]\n",
    "        \n",
    "        # print(f\"DEBUG {type(skeleton.dtype)}, {type(sensor.dtype)} {type(label.dtype)} \")\n",
    "        \n",
    "        if not isinstance(skeleton,torch.Tensor):\n",
    "            skeleton = torch.tensor(skeleton,dtype=torch.float32)\n",
    "            \n",
    "        if not isinstance(sensor,torch.Tensor):\n",
    "            sensor = torch.tensor(sensor,dtype=torch.float32)\n",
    "        \n",
    "        if not isinstance(label,torch.Tensor):\n",
    "            label = torch.tensor(label,dtype=torch.float32)\n",
    "            \n",
    "        skeleton = skeleton.permute(2,0,1) # skeleton [num_sample, (time, vertex, xyz)] -> [num_sample, (xyz, time, vertex)]\n",
    "        return skeleton,sensor,label\n",
    "    \n",
    "def custom_collate_fn(batch):\n",
    "    skeletons = [item[0] for item in batch]\n",
    "    sensors = [item[1] for item in batch]\n",
    "    labels = [item[2] for item in batch]\n",
    "\n",
    "    skeletons = torch.stack(skeletons)\n",
    "    sensors = torch.stack(sensors)\n",
    "    labels = torch.stack(labels)  # 例: ラベルが整数である場合\n",
    "\n",
    "    return skeletons, sensors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3af4a8a-81c1-4421-a952-00f7ecd7df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def KFold_load_dataset(data_files, batch_size, split_size=0.2):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    features, labels = [], []\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            fts, lbs = pickle.load(f)\n",
    "            features.append(fts)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    \n",
    "    print(features.shape)\n",
    "    print(labels.shape)\n",
    "    \n",
    "    set_of_train_loader,set_of_valid_loader = [],[]\n",
    "\n",
    "    if split_size > 0:\n",
    "        if split_size < 1:\n",
    "            n_splits = int(1/split_size)\n",
    "        else:\n",
    "            n_splits = split_size\n",
    "        skf = StratifiedKFold(n_splits,random_state=42, shuffle=True)\n",
    "        \n",
    "        for train_index, test_index in skf.split(features,labels):\n",
    "            train_set = data.TensorDataset(torch.tensor(features[train_index], dtype=torch.float32),torch.tensor(labels[train_index], dtype=torch.int64))\n",
    "            valid_set = data.TensorDataset(torch.tensor(features[test_index], dtype=torch.float32),torch.tensor(labels[test_index], dtype=torch.int64))\n",
    "            train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "            valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "            \n",
    "            set_of_train_loader.append(train_loader)\n",
    "            set_of_valid_loader.append(valid_loader)\n",
    "            \n",
    "    return set_of_train_loader, set_of_valid_loader\n",
    "\n",
    "def KFold_load_dataset_v2(data_files, batch_size, split_size=0.2):\n",
    "    \"\"\"Load data files into torch DataLoader with K-Fold splitting.\"\"\"\n",
    "    videos = []\n",
    "    features, sensors, labels = [], [], []\n",
    "    \n",
    "    # データの読み込み\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            vid, fts, sr, lbs = pickle.load(f)\n",
    "            videos += vid\n",
    "            features.append(fts)\n",
    "            sensors.append(sr)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs, sr\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    sensors = np.concatenate(sensors, axis=0)\n",
    "    \n",
    "    labels = labels.astype(np.float32)  # データ型の変換\n",
    "\n",
    "    set_of_train_loader, set_of_valid_loader = [], []\n",
    "\n",
    "    if split_size > 0:\n",
    "        if split_size < 1:\n",
    "            n_splits = int(1 / split_size)\n",
    "        else:\n",
    "            n_splits = split_size\n",
    "        \n",
    "        # skf = StratifiedKFold(n_splits, random_state=42, shuffle=True)\n",
    "        skf = KFold(n_splits, random_state=42, shuffle=True)\n",
    "        for train_index, test_index in skf.split(features, labels):\n",
    "            train_samples = [(features[i], sensors[i]) for i in train_index]\n",
    "            valid_samples = [(features[i], sensors[i]) for i in test_index]\n",
    "            \n",
    "            train_set = Skeleton_Sensor_Dataset(train_samples, labels[train_index])\n",
    "            valid_set = Skeleton_Sensor_Dataset(valid_samples, labels[test_index])\n",
    "            \n",
    "            train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "            valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "            \n",
    "            set_of_train_loader.append(train_loader)\n",
    "            set_of_valid_loader.append(valid_loader)\n",
    "    \n",
    "    return set_of_train_loader, set_of_valid_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d5bc12-a5fe-451e-a808-f7ea904d6b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_files, batch_size, random_state, split_size=0.3):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    features,sensors, labels = [], [], []\n",
    "    for fil in data_files:\n",
    "        # print(fil)\n",
    "        with open(fil, 'rb') as f:\n",
    "            _ ,fts,sr,lbs = pickle.load(f)\n",
    "            # videos += vid\n",
    "            features.append(fts)\n",
    "            sensors.append(sr)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs,sr\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    sensors = np.concatenate(sensors, axis=0)\n",
    "    # print(features.shape,labels.shape)\n",
    "    # print(f\"DEBUG {features.shape},{sensors.shape},{labels.shape}\")\n",
    "    labels = labels.astype(np.float32)\n",
    "    \n",
    "    samples = []\n",
    "    for feature,sensor in zip(features,sensors):\n",
    "        samples += [(feature,sensor)]\n",
    "    # samples = np.array(samples,dtype=object)\n",
    "    \n",
    "     # 乱数シードを生成\n",
    "    # random_state = np.random.randint(0, 100)\n",
    "    print(f\"Random State Used for Split: {random_state}\")\n",
    "    \n",
    "    if split_size > 0:\n",
    "        x_train, x_valid, y_train, y_valid = train_test_split(samples, labels, test_size=split_size,random_state=random_state)\n",
    "        \n",
    "        # train_set = data.TensorDataset(torch.tensor(x_train, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "        #                                torch.tensor(y_train, dtype=torch.float32))\n",
    "        # valid_set = data.TensorDataset(torch.tensor(x_valid, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "        #                                torch.tensor(y_valid, dtype=torch.float32))\n",
    "        train_set = Skeleton_Sensor_Dataset(x_train,y_train)\n",
    "        valid_set = Skeleton_Sensor_Dataset(x_valid,y_valid)\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "    else:\n",
    "        # train_set = data.TensorDataset(torch.tensor(features, dtype=torch.float32).permute(0, 3, 1, 2),\n",
    "        #                                torch.tensor(labels, dtype=torch.float32))\n",
    "        train_set = Skeleton_Sensor_Dataset(features,labels)\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = None\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def load_dataset_v2(data_files, batch_size, random_state, split_size=0.3):#0.2\n",
    "    \"\"\"Load data files into torch DataLoader with/without spliting train-test.\n",
    "    \"\"\"\n",
    "    videos = []\n",
    "    features,sensors, labels = [], [], []\n",
    "    for fil in data_files:\n",
    "        # print(fil)\n",
    "        with open(fil, 'rb') as f:\n",
    "            vid ,fts,sr, lbs = pickle.load(f)\n",
    "            videos += vid\n",
    "            features.append(fts)\n",
    "            sensors.append(sr)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs,sr\n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    sensors = np.concatenate(sensors, axis=0)\n",
    "    # print(features.shape,labels.shape)\n",
    "    # print(f\"DEBUG {features.shape},{sensors.shape},{labels.shape}\")\n",
    "    labels = labels.astype(np.float32) # dtype : object -> float32\n",
    "    \n",
    "    # random_state = np.random.randint(0, 100)\n",
    "    print(f\"Random State Used for Split: {random_state}\")\n",
    "    \n",
    "    if split_size > 0:\n",
    "        unique_video_names = np.unique(videos)\n",
    "        train_videos, test_videos= train_test_split(unique_video_names,test_size=split_size,random_state=random_state)\n",
    "\n",
    "        train_samples,valid_samples = [],[]\n",
    "        train_label,valid_label = [],[]\n",
    "        for video,feature,sensor,label in zip(videos,features,sensors,labels):\n",
    "            if video in train_videos:\n",
    "                train_samples += [(feature,sensor)]\n",
    "                train_label += [label]\n",
    "            else:\n",
    "                valid_samples += [(feature,sensor)]\n",
    "                valid_label += [label]\n",
    "        \n",
    "        train_set = Skeleton_Sensor_Dataset(train_samples,train_label)\n",
    "        valid_set = Skeleton_Sensor_Dataset(valid_samples,valid_label)\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True,)\n",
    "        valid_loader = data.DataLoader(valid_set, batch_size)\n",
    "    \n",
    "    else:\n",
    "        samples = []\n",
    "        for feature,sensor in zip(features,sensors):\n",
    "            samples += [(feature,sensor)]\n",
    "        train_set = Skeleton_Sensor_Dataset(samples,labels)\n",
    "        train_loader = data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "        valid_loader = None\n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8eaefe-20d9-483d-812c-849cfe45b7b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "Random State Used for Split: 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/egawa/anaconda3/envs/pt113/lib/python3.10/site-packages/torch/nn/modules/rnn.py:67: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params: 67195\n",
      "Epoch 0/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 9196/9196 [03:23<00:00, 45.11it/s,  loss: 0.3862, accu: 1.0000]\n",
      "valid: 100%|██████████| 3769/3769 [00:56<00:00, 66.48it/s,  loss: 2.8703, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4833, accu: 0.9498\n",
      " - Valid loss: 0.4501, accu: 0.9653\n",
      "0.9652925179092597\n",
      "Epoch 1/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 9196/9196 [03:23<00:00, 45.25it/s,  loss: 0.4838, accu: 0.9500]\n",
      "valid: 100%|██████████| 3769/3769 [00:57<00:00, 66.09it/s,  loss: 1.8440, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4406, accu: 0.9752\n",
      " - Valid loss: 0.4512, accu: 0.9624\n",
      "0.9652925179092597\n",
      "Epoch 2/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 9196/9196 [03:21<00:00, 45.64it/s,  loss: 0.4268, accu: 0.9500]\n",
      "valid: 100%|██████████| 3769/3769 [00:56<00:00, 66.18it/s,  loss: 2.4173, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4294, accu: 0.9817\n",
      " - Valid loss: 0.4436, accu: 0.9701\n",
      "0.9701014858052533\n",
      "Epoch 3/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 9196/9196 [03:28<00:00, 44.01it/s,  loss: 0.3758, accu: 1.0000]\n",
      "valid: 100%|██████████| 3769/3769 [00:58<00:00, 64.66it/s,  loss: 2.0472, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4237, accu: 0.9850\n",
      " - Valid loss: 0.4402, accu: 0.9704\n",
      "0.9703585168479703\n",
      "Epoch 4/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:  55%|█████▌    | 5069/9196 [01:45<01:27, 47.36it/s,  loss: 0.4156, accu: 1.0000]"
     ]
    }
   ],
   "source": [
    "#run the code\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "#二分割できる（訓練用とテスト用）\n",
    "\n",
    "#from pose_utils import motions_map\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# from Actionsrecognition.Models import *\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "save_folder = 'saved/HAR_sensor(conv)_load_datasetv2(7:3)_11'\n",
    "\n",
    "#device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"using\", device, \"device\")\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32 #32\n",
    "\n",
    "# DATA FILES.\n",
    "# Should be in format of\n",
    "#  inputs: (N_samples, time_steps, graph_node, channels),\n",
    "#  labels: (N_samples, num_class)\n",
    "#   and do some of normalizations on it. Default data create from:\n",
    "#       Data.create_dataset_(1-3).py\n",
    "# where\n",
    "#   time_steps: Number of frame input sequence, Default: 30\n",
    "#   graph_node: Number of node in skeleton, Default: 14\n",
    "#   channels: Inputs data (x, y and scores), Default: 3\n",
    "#   num_class: Number of pose class to train, Default: 7\n",
    "\n",
    "data_files = ['../Data_fall2/har30_1_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_2_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_3_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_4_sensor_new-set(labelXscrw).pkl',\n",
    "              # '../Data_fall2/har30_5_sensor_new-set(labelXscrw).pkl',]\n",
    "              '../Data_fall2/har30_6_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_7_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_8_sensor_new-set(labelXscrw).pkl',\n",
    "              # '../Data_fall2/har30_9_sensor_new-set(labelXscrw).pkl',]\n",
    "              '../Data_fall2/har30_10_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_11_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_12_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_13_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_14_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_15_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_16_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_17_sensor_new-set(labelXscrw).pkl']\n",
    "\n",
    "class_names = ['Falling_forwards_hands','Falling_forwards_knees','Falling_backwards','Falling_sidewards',\n",
    "              'Falling_sitting','Walking','Standing','Sitting','Picking','Jumping','Laying']\n",
    "# num_class = len(class_names)\n",
    "\n",
    "\n",
    "def accuracy_batch(y_pred, y_true):\n",
    "    return (y_pred.argmax(1) == y_true.argmax(1)).mean()\n",
    "\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #save_folder = os.path.join(os.path.dirname(), save_folder)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    # print('Start')\n",
    "    \n",
    "    random_state = np.random.randint(0, 100)  # 0から100までのランダムな整数を生成\n",
    "    with open(os.path.join(save_folder, \"random_state.txt\"), \"w\") as f:\n",
    "        f.write(f\"random_state: {random_state}\\n\")\n",
    "    \n",
    "    # DATA.\n",
    "    # set_of_train_loader,set_of_valid_loader = KFold_load_dataset_v2(data_files, batch_size,0.33)\n",
    "    # print(set_of_train_loader.size())\n",
    "    train_loader, valid_loader = load_dataset_v2(data_files[0:17], batch_size,random_state=random_state,split_size=0.3) \n",
    "    # for i,(train_loader,valid_loader) in enumerate(zip(set_of_train_loader,set_of_valid_loader)):\n",
    "        \n",
    "    dataloader = {'train': train_loader, 'valid': valid_loader, }\n",
    "\n",
    "    #print(train_loader.shape)\n",
    "\n",
    "    # MODEL.(list化)\n",
    "    graph_args = {'strategy': 'spatial'}\n",
    "    ## for sensor data\n",
    "    # model = BiLSTM(input_size=15,hidden_size=64,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\").to(device)\n",
    "    model = CNN_BiLSTM(hidden_size=32,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\").to(device)\n",
    "    # model = TwoStreamSpatialTemporalGraph(graph_args, 11).to(device)\n",
    "    n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"number of params: {n_parameters}\")\n",
    "    # model = TwoStreamSpatialTemporalGraph(graph_args, 2).to(device)\n",
    "    # graph_args = {'strategy': 'uniform'}\n",
    "    #graph_args = {'strategy': 'distance'}\n",
    "    # print(\"err\")\n",
    "    #model = TwoStreamSpatialTemporalGraph(graph_args, num_class).to(device)\n",
    "    #model = TwoStreamSpatialTemporalGraph(graph_args, 8).to(device)\n",
    "    optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    # losser = torch.nn.BCELoss() #fall or no_fall\n",
    "    losser = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # TRAINING.\n",
    "    loss_list = {'train': [], 'valid': []}\n",
    "    accu_list = {'train': [], 'valid': []}\n",
    "    best_acc = -1\n",
    "    for e in range(epochs):\n",
    "        print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model = set_training(model, True)\n",
    "            else:\n",
    "                model = set_training(model, False)\n",
    "\n",
    "            run_loss = 0.0\n",
    "            run_accu = 0.0\n",
    "            with tqdm(dataloader[phase], desc=phase) as iterator:\n",
    "                for info in iterator:\n",
    "                    # print(len(info))\n",
    "                    pts, ser, lbs = info\n",
    "                    # print(torch.any(torch.isnan(pts)))\n",
    "                    # Create motion input by distance of points (x, y) of the same node\n",
    "                    # in two frames.\n",
    "                    #print(\"err\")\n",
    "                    mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "\n",
    "                    mot = mot.to(device)\n",
    "                    pts = pts.to(device)\n",
    "                    ser = ser.to(device)\n",
    "                    # print(ser.size())\n",
    "                    # torch.Size([32, 30, 15])\n",
    "                    lbs = lbs.to(device)\n",
    "\n",
    "                    #print(pts.size())torch.Size([32, 3, 30, 14])\n",
    "                    #print(mot.size())torch.Size([32, 2, 29, 14])\n",
    "\n",
    "                    # Forward.\n",
    "                    # out = model((pts, mot))#タプル型\n",
    "                    out = model(ser) # for sensor data\n",
    "\n",
    "                    # out = stgcn_sensor_model((pts, mot,ser))\n",
    "\n",
    "                    #out = model(mot)#タプル型\n",
    "                    # print(lbs)\n",
    "\n",
    "                    # print(out)\n",
    "                    loss = losser(out, lbs)\n",
    "                    #print(\"err\")\n",
    "                    if phase == 'train':\n",
    "                        # Backward.\n",
    "                        model.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    run_loss += loss.item()\n",
    "                    accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                          lbs.detach().cpu().numpy())\n",
    "                    run_accu += accu\n",
    "\n",
    "                    iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                        loss.item(), accu))\n",
    "                    iterator.update()\n",
    "                    #break\n",
    "            loss_list[phase].append(run_loss / len(iterator))\n",
    "            accu_list[phase].append(run_accu / len(iterator))\n",
    "            #print(accu_list)\n",
    "            #print(torch.max(accu_list))\n",
    "        if(best_acc < accu_list['valid'][-1]):\n",
    "            best_acc = accu_list['valid'][-1]\n",
    "            best_model = copy.deepcopy(model)\n",
    "            torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "            #break\n",
    "\n",
    "        print('Summary epoch:\\n - Train loss: {:.4f}, accu: {:.4f}\\n - Valid loss:'\n",
    "        ' {:.4f}, accu: {:.4f}'.format(loss_list['train'][-1], accu_list['train'][-1],\n",
    "        loss_list['valid'][-1], accu_list['valid'][-1]))\n",
    "#             print(best_acc)\n",
    "#             plt.figure()\n",
    "#             plt.plot(list(range(len(loss_list['train']))),loss_list['train'],label=\"train_loss\")\n",
    "#             plt.plot(list(range(len(loss_list['valid']))),loss_list['valid'],label=\"valid_loss\")\n",
    "#             plt.legend()\n",
    "#             plt.savefig(os.path.join(save_folder, f'musa-model_of_loss_report_ur.png'))\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "\n",
    "#             plt.figure()\n",
    "#             plt.plot(list(range(len(accu_list['train']))),accu_list['train'],label=\"train_acc\")\n",
    "#             plt.plot(list(range(len(accu_list['valid']))),accu_list['valid'],label=\"valid_acc\")\n",
    "#             plt.legend()\n",
    "#             plt.savefig(os.path.join(save_folder, f'musa-model_of_acc_report.png'))\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "#             df = pd.DataFrame([loss_list['train'],loss_list['valid']]) \n",
    "#             df.to_csv(os.path.join(save_folder, f'musa-model_of_acc_report.csv'))\n",
    "\n",
    "#             df = pd.DataFrame([accu_list['train'],accu_list['valid']])\n",
    "#             df.to_csv(os.path.join(save_folder, f'musa-model_of_accu_report.csv'))\n",
    "#             torch.save(best_model.state_dict(), os.path.join(save_folder, f'musa-model_of_{best_acc:.4f}_UR.pth'))\n",
    "        print(best_acc)\n",
    "        plt.figure()\n",
    "        plt.plot(list(range(len(loss_list['train']))),loss_list['train'],label=\"train_loss\")\n",
    "        plt.plot(list(range(len(loss_list['valid']))),loss_list['valid'],label=\"valid_loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(save_folder, f'sensor-model_of_loss_report.png'))\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "\n",
    "        plt.figure()\n",
    "        plt.plot(list(range(len(accu_list['train']))),accu_list['train'],label=\"train_acc\")\n",
    "        plt.plot(list(range(len(accu_list['valid']))),accu_list['valid'],label=\"valid_acc\")\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(save_folder, f'sensor-model_of_acc_report.png'))\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        df = pd.DataFrame([loss_list['train'],loss_list['valid']]) \n",
    "        df.to_csv(os.path.join(save_folder, f'sensor-model_of_loss_report.csv'))\n",
    "\n",
    "        df = pd.DataFrame([accu_list['train'],accu_list['valid']])\n",
    "        df.to_csv(os.path.join(save_folder, f'sensor-model_of_acc_report.csv'))\n",
    "\n",
    "        # SAVE.\n",
    "        '''\n",
    "        if(best_acc < accu_list['valid'][-1]):\n",
    "            best_acc = accu_list['valid'][-1]\n",
    "            torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "            '''\n",
    "        '''\n",
    "        plot_graphs(list(loss_list.values()), list(loss_list.keys()),\n",
    "                        'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                            loss_list['train'][-1], loss_list['valid'][-1]\n",
    "                        ), 'Loss', xlim=[0, epochs],\n",
    "                        save=os.path.join(save_folder, 'loss_graph.png'))\n",
    "        plot_graphs(list(accu_list.values()), list(accu_list.keys()),\n",
    "                        'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                            accu_list['train'][-1], accu_list['valid'][-1]\n",
    "                        ), 'Accu', xlim=[0, epochs],\n",
    "                        save=os.path.join(save_folder, 'accu_graph.png'))\n",
    "        '''\n",
    "            #break\n",
    "\n",
    "    # del train_loader, valid_loader\n",
    "\n",
    "    #model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model.pth',map_location=torch.device('cpu'))))\n",
    "    model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model_best.pth')))\n",
    "    # EVALUATION.\n",
    "    #URのときは全部コメント\n",
    "    # model = set_training(model, False)\n",
    "    # data_file = data_files[1]\n",
    "    # eval_loader, _ = load_dataset([data_file], 32)\n",
    "\n",
    "    print('Evaluation.')\n",
    "    run_loss = 0.0\n",
    "    run_accu = 0.0\n",
    "    y_preds = []\n",
    "    y_trues = []\n",
    "    model = best_model\n",
    "    #with tqdm(eval_loader, desc='eval') as iterator:\n",
    "    #URFD\n",
    "    with tqdm(dataloader[phase], desc='eval') as iterator:\n",
    "        for pts,ser, lbs in iterator:\n",
    "            # print(lbs)\n",
    "            mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "            mot = mot.to(device)\n",
    "            pts = pts.to(device)\n",
    "            ser = ser.to(device)\n",
    "            lbs = lbs.to(device)\n",
    "\n",
    "            # out = model((pts, mot)) # for skeleton data\n",
    "            out = model(ser) # for sensor data\n",
    "            #out = model(mot)################\n",
    "            loss = losser(out, lbs)\n",
    "\n",
    "            run_loss += loss.item()\n",
    "            accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                  lbs.detach().cpu().numpy())\n",
    "            run_accu += accu\n",
    "\n",
    "            y_preds.extend(out.argmax(1).detach().cpu().numpy())\n",
    "            y_trues.extend(lbs.argmax(1).cpu().numpy())\n",
    "\n",
    "            iterator.set_postfix_str('loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                loss.item(), accu))\n",
    "            iterator.update()\n",
    "\n",
    "    run_loss = run_loss / len(iterator)\n",
    "    run_accu = run_accu / len(iterator)\n",
    "    print('Eval Loss {:.4f}, Accu: {:.4f}'.format(run_loss, run_accu))\n",
    "    print('Precision:', precision_score(y_trues, y_preds,average='micro'))\n",
    "    print('Recall:', recall_score(y_trues, y_preds,average='micro'))\n",
    "    print('F1-score:', f1_score(y_trues, y_preds,average='micro'))\n",
    "#     tn, fp, fn, tp = metrics.confusion_matrix(y_trues, y_preds).ravel()\n",
    "#     specificity  = tn / (tn + fp)\n",
    "#     print('Specificity:', specificity)\n",
    "    print(classification_report(y_trues, y_preds,digits=5))\n",
    "    report=classification_report(y_trues,  y_preds, digits=5,output_dict=True)\n",
    "    report_df = pd.DataFrame(report).T\n",
    "    report_df.to_csv(os.path.join(save_folder, f'sensor-model_of_{run_accu:.4f}_report.csv'))\n",
    "\n",
    "    cmx_data = confusion_matrix(y_trues, y_preds)\n",
    "\n",
    "    df_cmx = pd.DataFrame(cmx_data)\n",
    "\n",
    "    plt.figure()\n",
    "    sns.heatmap(df_cmx, annot=True)\n",
    "    plt.savefig(os.path.join(save_folder, f'sensor-model_ofs_confution_matrix.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff05139a-b0e7-467a-b57a-1680b3df8a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataloader(data_files, batch_size, phase=\"train\"):\n",
    "    videos=[]\n",
    "    features, sensors, labels = [], [], []\n",
    "    \n",
    "    # データの読み込み\n",
    "    for fil in data_files:\n",
    "        with open(fil, 'rb') as f:\n",
    "            vid, fts, sr, lbs = pickle.load(f)\n",
    "            videos += vid\n",
    "            features.append(fts)\n",
    "            sensors.append(sr)\n",
    "            labels.append(lbs)\n",
    "        del fts, lbs, sr\n",
    "    \n",
    "    features = np.concatenate(features, axis=0)\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "    sensors = np.concatenate(sensors, axis=0)\n",
    "    \n",
    "    labels = labels.astype(np.float32)  # データ型の変換\n",
    "\n",
    "    data_sample = [(feature,sensor) for feature,sensor in zip(features,sensors)]\n",
    "    dataset = Skeleton_Sensor_Dataset(data_sample, labels)\n",
    "    dataloader = data.DataLoader(dataset, \n",
    "                                 batch_size, \n",
    "                                 shuffle=True if phase ==\"train\" else False,\n",
    "                                 drop_last=True if phase==\"train\" else False\n",
    "                                )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e660b8-19a5-47be-adc7-c1b541abb124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda device\n",
      "number of params: 14483\n",
      "Epoch 0/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [01:05<00:00, 117.43it/s,  loss: 0.4772, accu: 0.9688]\n",
      "valid: 100%|██████████| 2505/2505 [00:15<00:00, 157.14it/s,  loss: 2.6930, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4646, accu: 0.9640\n",
      " - Valid loss: 2.7337, accu: 0.1962\n",
      "0.1962450099800399\n",
      "Epoch 1/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [00:58<00:00, 132.00it/s,  loss: 0.4143, accu: 0.9688]\n",
      "valid: 100%|██████████| 2505/2505 [00:15<00:00, 162.28it/s,  loss: 2.3618, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4135, accu: 0.9925\n",
      " - Valid loss: 2.5022, accu: 0.2063\n",
      "0.2063498003992016\n",
      "Epoch 2/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [00:58<00:00, 132.06it/s,  loss: 0.4303, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:15<00:00, 165.74it/s,  loss: 2.7018, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4060, accu: 0.9957\n",
      " - Valid loss: 2.3082, accu: 0.2140\n",
      "0.21404690618762476\n",
      "Epoch 3/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [00:58<00:00, 131.19it/s,  loss: 0.3802, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:16<00:00, 153.29it/s,  loss: 3.0693, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4023, accu: 0.9971\n",
      " - Valid loss: 2.2747, accu: 0.2344\n",
      "0.2343812375249501\n",
      "Epoch 4/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [00:59<00:00, 129.45it/s,  loss: 0.3937, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:15<00:00, 158.78it/s,  loss: 2.6380, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.4001, accu: 0.9978\n",
      " - Valid loss: 2.3185, accu: 0.2254\n",
      "0.2343812375249501\n",
      "Epoch 5/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [00:58<00:00, 132.22it/s,  loss: 0.3735, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:15<00:00, 165.10it/s,  loss: 2.4803, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3985, accu: 0.9984\n",
      " - Valid loss: 2.3110, accu: 0.2367\n",
      "0.23668912175648701\n",
      "Epoch 6/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 100%|██████████| 7672/7672 [00:58<00:00, 130.64it/s,  loss: 0.4186, accu: 1.0000]\n",
      "valid: 100%|██████████| 2505/2505 [00:22<00:00, 110.78it/s,  loss: 2.7889, accu: 0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary epoch:\n",
      " - Train loss: 0.3975, accu: 0.9986\n",
      " - Valid loss: 2.2811, accu: 0.2357\n",
      "0.23668912175648701\n",
      "Epoch 7/99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   1%|▏         | 99/7672 [00:01<01:22, 92.10it/s,  loss: 0.4045, accu: 1.0000] "
     ]
    }
   ],
   "source": [
    "#run the code\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from shutil import copyfile\n",
    "from tqdm import tqdm\n",
    "from torch.utils import data\n",
    "from torch.optim.adadelta import Adadelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "from skeleton_transformer import SkeletonTransformer\n",
    "\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "#二分割できる（訓練用とテスト用）\n",
    "\n",
    "#from pose_utils import motions_map\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "# from Actionsrecognition.Models import *\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    KFold,\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "save_folder = 'saved/GSTCAN_HAR_newKfold_sensor(Lstm)'\n",
    "\n",
    "#device = 'cuda'\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"using\", device, \"device\")\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 32 #32\n",
    "\n",
    "# DATA FILES.\n",
    "# Should be in format of\n",
    "#  inputs: (N_samples, time_steps, graph_node, channels),\n",
    "#  labels: (N_samples, num_class)\n",
    "#   and do some of normalizations on it. Default data create from:\n",
    "#       Data.create_dataset_(1-3).py\n",
    "# where\n",
    "#   time_steps: Number of frame input sequence, Default: 30\n",
    "#   graph_node: Number of node in skeleton, Default: 14\n",
    "#   channels: Inputs data (x, y and scores), Default: 3\n",
    "#   num_class: Number of pose class to train, Default: 7\n",
    "\n",
    "data_files = ['../Data_fall2/har30_1_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_2_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_3_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_4_sensor_new-set(labelXscrw).pkl',\n",
    "              # '../Data_fall2/har30_5_sensor_new-set(labelXscrw).pkl',]\n",
    "              '../Data_fall2/har30_6_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_7_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_8_sensor_new-set(labelXscrw).pkl',\n",
    "              # '../Data_fall2/har30_9_sensor_new-set(labelXscrw).pkl',]\n",
    "              '../Data_fall2/har30_10_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_11_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_12_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_13_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_14_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_15_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_16_sensor_new-set(labelXscrw).pkl',\n",
    "              '../Data_fall2/har30_17_sensor_new-set(labelXscrw).pkl']\n",
    "\n",
    "class_names = ['Falling_forwards_hands','Falling_forwards_knees','Falling_backwards','Falling_sidewards',\n",
    "              'Falling_sitting','Walking','Standing','Sitting','Picking','Jumping','Laying']\n",
    "# num_class = len(class_names)\n",
    "\n",
    "def k_fold_cross_subject_HAR_UP(data_files):\n",
    "    f_fold = {}\n",
    "    data_files = np.array(data_files)\n",
    "    \n",
    "    for i,(train_idx,test_idx) in enumerate(KFold(n_splits=5,shuffle=True,random_state=42).split(data_files)):\n",
    "        train_pkl, test_pkl = data_files[train_idx], data_files[test_idx]\n",
    "        \n",
    "        train_subset_pkl, valid_subset_pkl = train_test_split(train_pkl,test_size=3,shuffle=True,random_state=42)\n",
    "        \n",
    "        f_fold[f\"{i+1}_fold\"]={\n",
    "            'train':train_subset_pkl,\n",
    "            'valid':valid_subset_pkl,\n",
    "            'test':test_pkl,\n",
    "        }\n",
    "        \n",
    "    return f_fold\n",
    "\n",
    "# f_fold[\"1_fold\"] = {\"train\":['../Data_fall2/har30_1_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_2_sensor_new-set(labelXscrw).pkl''../Data_fall2/har30_3_sensor_new-set(labelXscrw).pkl',...],\n",
    "#                     \"valid\":['../Data_fall2/har30_7_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_8_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_9_sensor_new-set(labelXscrw).pkl',...],\n",
    "#                     \"test\":['../Data_fall2/har30_10_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_11_sensor_new-set(labelXscrw).pkl','../Data_fall2/har30_12_sensor_new-set(labelXscrw).pkl',...]\n",
    "#                    }\n",
    "                    \n",
    "        \n",
    "\n",
    "\n",
    "def accuracy_batch(y_pred, y_true):\n",
    "    return (y_pred.argmax(1) == y_true.argmax(1)).mean()\n",
    "\n",
    "\n",
    "def set_training(model, mode=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = mode\n",
    "    model.train(mode)\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    #save_folder = os.path.join(os.path.dirname(), save_folder)\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "    # print('Start')\n",
    "\n",
    "    # DATA.\n",
    "    # set_of_train_loader,set_of_valid_loader = KFold_load_dataset_v2(data_files, batch_size,0.33)\n",
    "    # print(set_of_train_loader.size())\n",
    "    # train_loader, valid_loader = load_dataset_v2(data_files[0:1], batch_size,split_size=0.2) \n",
    "    # for i,(train_loader,valid_loader) in enumerate(zip(set_of_train_loader,set_of_valid_loader)):\n",
    "    \n",
    "    kfold_dict = k_fold_cross_subject_HAR_UP(data_files)  \n",
    "    for i in kfold_dict.keys():\n",
    "        \n",
    "        dataloader = dict()\n",
    "        for phase in ['train','valid','test']:\n",
    "            pkl_files = kfold_dict[i][phase]\n",
    "            dataloader[phase] = build_dataloader(pkl_files,batch_size, phase=phase)\n",
    "\n",
    "\n",
    "        # MODEL.(list化)\n",
    "        graph_args = {'strategy': 'spatial'}\n",
    "        ## for sensor data\n",
    "        model = BiLSTM(input_size=15,hidden_size=32,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\").to(device)\n",
    "        # model = CNN_BiLSTM(hidden_size=32,num_layers=1,dropout_prob=0.3,num_classes=11,feature=\"mean\").to(device)\n",
    "        # model = SkeletonTransformer(in_channels=3,n_joints=14,seq_len=30,num_classes=11,embedding_dim=32,n_block=6,head_dim=16,n_heads=8).to(device)\n",
    "        # model = TwoStreamSpatialTemporalGraph(graph_args, 11).to(device)\n",
    "        # model = E\n",
    "        n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"number of params: {n_parameters}\")\n",
    "        # model = TwoStreamSpatialTemporalGraph(graph_args, 2).to(device)\n",
    "        # graph_args = {'strategy': 'uniform'}\n",
    "        #graph_args = {'strategy': 'distance'}\n",
    "        # print(\"err\")\n",
    "        #model = TwoStreamSpatialTemporalGraph(graph_args, num_class).to(device)\n",
    "        #model = TwoStreamSpatialTemporalGraph(graph_args, 8).to(device)\n",
    "        optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "        # losser = torch.nn.BCELoss() #fall or no_fall\n",
    "        losser = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # TRAINING.\n",
    "        loss_list = {'train': [], 'valid': []}\n",
    "        accu_list = {'train': [], 'valid': []}\n",
    "        best_acc = -1\n",
    "        for e in range(epochs):\n",
    "            print('Epoch {}/{}'.format(e, epochs - 1))\n",
    "            for phase in ['train', 'valid']:\n",
    "                if phase == 'train':\n",
    "                    model = set_training(model, True)\n",
    "                else:\n",
    "                    model = set_training(model, False)\n",
    "\n",
    "                run_loss = 0.0\n",
    "                run_accu = 0.0\n",
    "                with tqdm(dataloader[phase], desc=phase) as iterator:\n",
    "                    for info in iterator:\n",
    "                        # print(len(info))\n",
    "                        pts, ser, lbs = info\n",
    "                        # print(torch.any(torch.isnan(pts)))\n",
    "                        # Create motion input by distance of points (x, y) of the same node\n",
    "                        # in two frames.\n",
    "                        #print(\"err\")\n",
    "                        mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "\n",
    "                        mot = mot.to(device)\n",
    "                        pts = pts.to(device)\n",
    "                        ser = ser.to(device)\n",
    "                        # print(ser.size())\n",
    "                        # torch.Size([32, 30, 15])\n",
    "                        lbs = lbs.to(device)\n",
    "\n",
    "                        #print(pts.size())torch.Size([32, 3, 30, 14])\n",
    "                        #print(mot.size())torch.Size([32, 2, 29, 14])\n",
    "\n",
    "                        # Forward.\n",
    "                        # out = model((pts, mot))#タプル型\n",
    "                        out = model(ser) # for sensor data\n",
    "                        # pts = pts.unsqueeze(-1)\n",
    "                        # out = model(pts)\n",
    "                        # out = model((pts, mot, ser))\n",
    "                        # out = stgcn_sensor_model((pts, mot,ser))\n",
    "\n",
    "                        #out = model(mot)#タプル型\n",
    "                        # print(lbs)\n",
    "\n",
    "                        # print(out)\n",
    "                        loss = losser(out, lbs)\n",
    "                        #print(\"err\")\n",
    "                        if phase == 'train':\n",
    "                            # Backward.\n",
    "                            model.zero_grad()\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                        run_loss += loss.item()\n",
    "                        accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                              lbs.detach().cpu().numpy())\n",
    "                        run_accu += accu\n",
    "\n",
    "                        iterator.set_postfix_str(' loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                            loss.item(), accu))\n",
    "                        iterator.update()\n",
    "                        #break\n",
    "                loss_list[phase].append(run_loss / len(iterator))\n",
    "                accu_list[phase].append(run_accu / len(iterator))\n",
    "                #print(accu_list)\n",
    "                #print(torch.max(accu_list))\n",
    "            if(best_acc < accu_list['valid'][-1]):\n",
    "                best_acc = accu_list['valid'][-1]\n",
    "                best_model = copy.deepcopy(model)\n",
    "                torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "                #break\n",
    "\n",
    "            print('Summary epoch:\\n - Train loss: {:.4f}, accu: {:.4f}\\n - Valid loss:'\n",
    "            ' {:.4f}, accu: {:.4f}'.format(loss_list['train'][-1], accu_list['train'][-1],\n",
    "            loss_list['valid'][-1], accu_list['valid'][-1]))\n",
    "#             print(best_acc)\n",
    "#             plt.figure()\n",
    "#             plt.plot(list(range(len(loss_list['train']))),loss_list['train'],label=\"train_loss\")\n",
    "#             plt.plot(list(range(len(loss_list['valid']))),loss_list['valid'],label=\"valid_loss\")\n",
    "#             plt.legend()\n",
    "#             plt.savefig(os.path.join(save_folder, f'musa-model_of_loss_report_ur.png'))\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "\n",
    "#             plt.figure()\n",
    "#             plt.plot(list(range(len(accu_list['train']))),accu_list['train'],label=\"train_acc\")\n",
    "#             plt.plot(list(range(len(accu_list['valid']))),accu_list['valid'],label=\"valid_acc\")\n",
    "#             plt.legend()\n",
    "#             plt.savefig(os.path.join(save_folder, f'musa-model_of_acc_report.png'))\n",
    "#             plt.clf()\n",
    "#             plt.close()\n",
    "#             df = pd.DataFrame([loss_list['train'],loss_list['valid']]) \n",
    "#             df.to_csv(os.path.join(save_folder, f'musa-model_of_acc_report.csv'))\n",
    "\n",
    "#             df = pd.DataFrame([accu_list['train'],accu_list['valid']])\n",
    "#             df.to_csv(os.path.join(save_folder, f'musa-model_of_accu_report.csv'))\n",
    "#             torch.save(best_model.state_dict(), os.path.join(save_folder, f'musa-model_of_{best_acc:.4f}_UR.pth'))\n",
    "            print(best_acc)\n",
    "            plt.figure()\n",
    "            plt.plot(list(range(len(loss_list['train']))),loss_list['train'],label=\"train_loss\")\n",
    "            plt.plot(list(range(len(loss_list['valid']))),loss_list['valid'],label=\"valid_loss\")\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_folder, f'stgcn-model_{i }of{len(kfold_dict)}_loss_report.png'))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(list(range(len(accu_list['train']))),accu_list['train'],label=\"train_acc\")\n",
    "            plt.plot(list(range(len(accu_list['valid']))),accu_list['valid'],label=\"valid_acc\")\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(save_folder, f'stgcn-model_{i}of{len(kfold_dict)}_acc_report.png'))\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "            df = pd.DataFrame([loss_list['train'],loss_list['valid']]) \n",
    "            df.to_csv(os.path.join(save_folder, f'stgcn-model_{i}of{len(kfold_dict)}_acc_report.csv'))\n",
    "\n",
    "            df = pd.DataFrame([accu_list['train'],accu_list['valid']])\n",
    "            df.to_csv(os.path.join(save_folder, f'stgcn-model_{i}of{len(kfold_dict)}_accu_report.csv'))\n",
    "\n",
    "            # SAVE.\n",
    "            '''\n",
    "            if(best_acc < accu_list['valid'][-1]):\n",
    "                best_acc = accu_list['valid'][-1]\n",
    "                torch.save(model.state_dict(), os.path.join(save_folder, 'tsstg-model_best.pth'))\n",
    "                '''\n",
    "            '''\n",
    "            plot_graphs(list(loss_list.values()), list(loss_list.keys()),\n",
    "                            'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                                loss_list['train'][-1], loss_list['valid'][-1]\n",
    "                            ), 'Loss', xlim=[0, epochs],\n",
    "                            save=os.path.join(save_folder, 'loss_graph.png'))\n",
    "            plot_graphs(list(accu_list.values()), list(accu_list.keys()),\n",
    "                            'Last Train: {:.2f}, Valid: {:.2f}'.format(\n",
    "                                accu_list['train'][-1], accu_list['valid'][-1]\n",
    "                            ), 'Accu', xlim=[0, epochs],\n",
    "                            save=os.path.join(save_folder, 'accu_graph.png'))\n",
    "            '''\n",
    "                #break\n",
    "\n",
    "        # del train_loader, valid_loader\n",
    "\n",
    "        #model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model.pth',map_location=torch.device('cpu'))))\n",
    "        model.load_state_dict(torch.load(os.path.join(save_folder, 'tsstg-model_best.pth')))\n",
    "        # EVALUATION.\n",
    "        #URのときは全部コメント\n",
    "        # model = set_training(model, False)\n",
    "        # data_file = data_files[1]\n",
    "        # eval_loader, _ = load_dataset([data_file], 32)\n",
    "\n",
    "        print('Evaluation.')\n",
    "        run_loss = 0.0\n",
    "        run_accu = 0.0\n",
    "        y_preds = []\n",
    "        y_trues = []\n",
    "        model = best_model\n",
    "        #with tqdm(eval_loader, desc='eval') as iterator:\n",
    "        #URFD\n",
    "        with tqdm(dataloader['test'], desc='eval') as iterator:\n",
    "            for pts,ser, lbs in iterator:\n",
    "                # print(lbs)\n",
    "                mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "                mot = mot.to(device)\n",
    "                pts = pts.to(device)\n",
    "                ser = ser.to(device)\n",
    "                lbs = lbs.to(device)\n",
    "\n",
    "                # out = model((pts, mot)) # for skeleton data\n",
    "                out = model(ser) # for sensor data\n",
    "                # pts = pts.unsqueeze(-1)\n",
    "                # out = model(pts)\n",
    "                # out = model((pts, mot, ser))\n",
    "                # out = model(mot)################\n",
    "                loss = losser(out, lbs)\n",
    "\n",
    "                run_loss += loss.item()\n",
    "                accu = accuracy_batch(out.detach().cpu().numpy(),\n",
    "                                      lbs.detach().cpu().numpy())\n",
    "                run_accu += accu\n",
    "\n",
    "                y_preds.extend(out.argmax(1).detach().cpu().numpy())\n",
    "                y_trues.extend(lbs.argmax(1).cpu().numpy())\n",
    "\n",
    "                iterator.set_postfix_str('loss: {:.4f}, accu: {:.4f}'.format(\n",
    "                    loss.item(), accu))\n",
    "                iterator.update()\n",
    "\n",
    "        run_loss = run_loss / len(iterator)\n",
    "        run_accu = run_accu / len(iterator)\n",
    "        print('Eval Loss {:.4f}, Accu: {:.4f}'.format(run_loss, run_accu))\n",
    "        print('Precision:', precision_score(y_trues, y_preds,average='micro'))\n",
    "        print('Recall:', recall_score(y_trues, y_preds,average='micro'))\n",
    "        print('F1-score:', f1_score(y_trues, y_preds,average='micro'))\n",
    "    #     tn, fp, fn, tp = metrics.confusion_matrix(y_trues, y_preds).ravel()\n",
    "    #     specificity  = tn / (tn + fp)\n",
    "    #     print('Specificity:', specificity)\n",
    "        print(classification_report(y_trues, y_preds,digits=5))\n",
    "        report=classification_report(y_trues,  y_preds, digits=5,output_dict=True)\n",
    "        report_df = pd.DataFrame(report).T\n",
    "        report_df.to_csv(os.path.join(save_folder, f'GSTCAN_{i}of{len(kfold_dict)}_{best_acc:.4f}_report.csv'))\n",
    "\n",
    "        cmx_data = confusion_matrix(y_trues, y_preds)\n",
    "\n",
    "        df_cmx = pd.DataFrame(cmx_data)\n",
    "\n",
    "        plt.figure()\n",
    "        sns.heatmap(df_cmx, annot=True)\n",
    "        plt.savefig(os.path.join(save_folder, f'GSTCAN_{i}of{len(kfold_dict)}_confution_matrix.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2182e94-9098-4695-bbe4-fb08dca700b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(phase)Classification_Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968bdda-17ee-4890-a6da-7696a116332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader, _ = load_dataset(data_files[0:1], batch_size) #batch_size = 32\n",
    "\n",
    "valid_loader, train_loader_ = load_dataset(data_files[:1], batch_size, 0.2)\n",
    "#print(\"err\")\n",
    "train_loader = data.DataLoader(data.ConcatDataset([train_loader.dataset, train_loader_.dataset]),\n",
    "                               batch_size, shuffle=True)\n",
    "dataloader = {'train': train_loader, 'valid': valid_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60102b09-09ed-436b-a786-b0f5307fddc2",
   "metadata": {},
   "outputs": [],
   "source": [
    " with tqdm(dataloader[phase], desc='eval') as iterator:\n",
    "        for pts, lbs in iterator:\n",
    "            mot = pts[:, :2, 1:, :] - pts[:, :2, :-1, :]\n",
    "            print(mot.shape)\n",
    "            print(lbs)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b285d-a9a1-4aba-bdfb-7e642ace17a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "print(\"__file__:{}\".format(os.path.dirname(__file__)))\n",
    "print(\"dirname :{}\".format(os.path.dirname(__file__)))\n",
    "print(\"basename:{}\".format(os.path.basename(__file__)))\n",
    "print(\"files   :{}\".format(os.listdir(os.path.dirname(__file__))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c15c1b-ef62-4ef7-94ff-c73f2776332a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt113",
   "language": "python",
   "name": "pt113"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
